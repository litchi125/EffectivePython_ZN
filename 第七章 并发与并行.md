# 第七章 并发与并行

​		并发性能够让计算机看起来同时多很多事情。例如，在一台只有一个CPU内核的计算机上，如果有哪个程序在单处理器上运行，操作系统就会迅速变化。这样做时，操作系统交错地执行程序，这就展示了一种多个程序同时进行的假象。

​		相反，并行性涉到在同一时间做许多不同的事情。具有多个CPU内核的计算机可以同时执行多个程序。每个CPU内核运行一个独立程序的指令，这允许每个程序在同一时刻前进。

​		在单个程序中，并发性是一种使程序员更容易解决某些类型问题的工具。并发程序支持许多不同的执行路径，包括独立的I/O流，以一种似乎同时和独立的方式向前推进。

​		并行性和并发性之间的关键区别在于加速。当一个程序中有两条不同的路径并行前进时，完成全部工作所需要的时间就减少了一半；执行速度快了两倍。相比之下，并发程序可能会运行数千条看似并行的独立执行路径，但对总体工作没有提供加速。

​		Python有多种风格方式能够使得并发程序变得很容易写。线程支持相对较少的并发性，而协程支持大量的并发函数。Python还可以通过系统调用、子进程和C扩展完成并行工作。但是让并发的Python代码真正并行运行是非常困难的。了解如何在这不同的情况下最好的利用Python是最重要的。

## 第52条 使用subprocess管理子进程

​		Python有运行和管理子进程的可靠库。这使得它成为其他工具(如命令行实用程序)结合在一起的一种很好的语言。当现有的shell脚本变得复杂时(随着时间的推移，他们经常会变得复杂)，出于可读性和可维护性的考虑，将他们分别使用Python重写是一个自然的选择。

​		由Python启动子进程能够并行运行，是我们能够使用Python消耗机器的所有CPU内核，并最大限度地提高程序的吞吐量。虽然Python本身可能受CPU限制(参见第53条)，但使用Python来驱动和协调CPU密集型工作的负载是很容易的。

​		Python有很多方式来运行子进程(例如，os.open，os.exex*)，但是管理子进程的最佳选择是使用子进程内置模块。用子进程运行子进程非常简单。这里，使用模块的run convenience函数来启动进程，读取其输出，并验证它是否终止彻底:

```python
import subprocess
# Enable these lines to make this example work on Windows
# import os
# os.environ['COMSPEC'] = 'powershell'

result = subprocess.run(
    ['echo', 'Hello from the child!'],
    capture_output=True,
    # Enable this line to make this example work on Windows
    # shell=True,
    encoding='utf-8', shell=True)

result.check_returncode()  # No exception means it exited cleanly
print(result.stdout)
>>>
"Hello from the child!"
```

***

**注意**

​		本项目中的示例假设系统存在echo、sleep、OpenSSL命令可用。在Windows上，情况并非如此。关于如何在Windows上运行这些代码片段，参阅完整示例代码。

***

​		子进程独立于父进程(Python解析器)而运行。如果使用popen类而不是run函数创建一个子进程，可以在Python做其他工作时轮询子进程。

~~~python
proc = subprocess.Popen(['sleep', '1'], shell=True)
while proc.poll() is None:
    print('Working...')
    # Some time-consuming work here
	...
print('Exit status', proc.poll())
>>>
Working...
Working...
Working...
Working...
Working...
Working...
...
~~~

​		将子进程与父进程解耦可释放父进程以并行地运行许多子进程。在这里，通过使用Popen提前启动所有的子进程来做到这一点：

~~~python
import time
start = time.time()
sleep_procs = []
for _ in range(10):
    proc = subprocess.Popen(['sleep', '1'], shell = True)
    sleep_procs.append(proc)
~~~

​		之后，等待他们完成I/O，用通信方法结束：

~~~python
import time

start = time.time()
sleep_procs = []
for _ in range(10):
    proc = subprocess.Popen(['sleep', '1'], shell=True)
    sleep_procs.append(proc)

for proc in sleep_procs:
    proc.communicate()
end = time.time()
delta = end - start
print(f'Finished in {delta:.3} seconds')
>>>
Finished in 0.111 seconds
~~~

​		如果这些进程按照顺序进行，总的延迟将会是10s或更多，而不是测试的结果。

​		还可以将数据从Python程序传输到子进程，并检查其输出。这允许使用许多其他程序并行运行工作。例如，假设要使用OpenSSL命令工具加密一些数据。使用命令行参数和I/O管道启动子进程很简单。

~~~python
import os
# On Windows, after installing OpenSSL, you may need to
# alias it in your PowerShell path with a command like:
# $env:path = $env:path + ";C:\Program Files\OpenSSL-Win64\bin"

def run_encrypt(data):
    env = os.environ.copy()
    env['password'] = 'zf7ShyBhZOraQDdE/FiZpm/m/8f9X+M1'
    proc = subprocess.Popen(
        ['openssl', 'enc', '-des3', '-pass', 'env:password'],
        env=env,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
    	shell=True)
    proc.stdin.write(data)
    proc.stdin.flush()  # Ensure that the child gets input
    return proc

~~~

​		在这里，将随机字节通过管道传输到加密函数中，但实际上，这个输入管道将从用户输入、文件句柄、网络套接字等输入数据:

~~~python
procs = []
for _ in range(3):
    data = os.urandom(10)
    proc = run_encrypt(data)
    procs.append(proc)
~~~

​		子进程并行运行并使用它们的输入。在这里，等待它们完成后，然后检索它们的最终输出。输出是随机的：

~~~python
for proc in procs:
    out, _ = proc.communicate()
    print(out[-10:])
>>>
b't\xcb|j\x8b\xf0\x96P\x85\xa0'
b'\xd5M\xd1.\xa5\xb4C\xb0\xd3_'
b'3\xc4]\x07YB\xd7X\xf1\xd8'

~~~

​		还可以创建并行进程链，就像UNIX管道一样，将一个子进程的输出连接到另一个子进程的输入，等等。下面是一个函数，它将openssl命令行工具作为子进程启动，以生成输入流的Whirlpool散列：

~~~python
def run_hash(input_stdin):
    return subprocess.Popen(
        ['openssl', 'dgst', '-whirlpool', '-binary'],
        stdin=input_stdin,
        stdout=subprocess.PIPE,
    	shell=True)
~~~

​		现在，可以启动一组进程来加密一些数据，然后启动另一组进程来对其加密的输出进行散列。这里必须注意，启动子进程管道的Python解释器进程是如何保留上游进程的stdout实例的:

~~~python
encrypt_procs = []
hash_procs = []
for _ in range(3):
    data = os.urandom(100)

    encrypt_proc = run_encrypt(data)
    encrypt_procs.append(encrypt_proc)

    hash_proc = run_hash(encrypt_proc.stdout)
    hash_procs.append(hash_proc)

    # Ensure that the child consumes the input stream and
    # the communicate() method doesn't inadvertently steal
    # input from the child. Also lets SIGPIPE propagate to
    # the upstream process if the downstream process dies.
    encrypt_proc.stdout.close()
    encrypt_proc.stdout = None
~~~

​		一旦启动子进程，它们之间的I/O将自动发生。所需要做的就是等待他们完成并打印最终输出:

```python
for proc in encrypt_procs:
    proc.communicate()
    assert proc.returncode == 0

for proc in hash_procs:
    out, _ = proc.communicate()
    print(out[-10:])
    assert proc.returncode == 0
>>>
b'\xe2j\x98h\xfd\xec\xe7T\xd84'
b'\xf3.i\x01\xd74|\xf2\x94E'
b'5_n\xc3-\xe6j\xeb[i'
```

​		如果担心子进程永远不会完成或以某种方式阻塞输入或输出管道，可以将timeout参数传递给communicate方法。如果子进程没有在指定的时间内完成，就会引发一个异常，从而可以终止行为不正常的子进程:

```python
# Use this line instead to make this example work on Windows
# proc = subprocess.Popen(['sleep', '10'], shell=True)
proc = subprocess.Popen(['sleep', '10'], shell=True)
try:
    proc.communicate(timeout=0.1)
except subprocess.TimeoutExpired:
    proc.terminate()
    proc.wait()

print('Exit status', proc.poll())
```

**要点**

* 使用子进程模块来运行子进程并管理它们的输入和输出流
* 子进程与Python解释器并行运行，使得能够最大限度地利用CPU内核
* run便利函数的简单使用，Popen类的高级使用，如unix风格的管道
* 使用通信方法的timeout参数来避免死锁和子进程挂起

## 第53条 使用线程阻塞I/O以避免并行

​		**Python的标准实现成为CPython。CPython以两步运行Python。首先，他将源文本解析并编译成字节码，这是作为8位指令的程序的低级表示。(然而，从Python3.6开始，他在技术上是带有16位指令的字节码，但其意思是相同的。)然后，CPython使用基于堆栈的解析器运行字节码。字节码解释器的状态必须在Python程序执行时保持一致。CPython通过一种称为全局解析器(GIL)的机制来加强一致性。**

​		本质上，GIL是一个互斥锁，它防止CPython受到抢占式多线程影响，抢占式多线程是指一个线程通过中断另一个线程来控制一个程序。这样的中断如果发生在意外的时间，可能会破坏解释器状态(例如，垃圾收集引用计数)。GIL防止了这些中断，并确保每个字节码指令与CPython实现及其C扩展模块正常工作。

​		GIL有一个重要的副作用。对于用c++或Java这样的语言编写的程序，拥有多个执行线程意味着一个程序可以同时使用多个CPU内核。尽管Python支持多个执行线程，但GIL每次只会让其中一个线程取得进展。这意味着当使用线程来进行并行计算并加速Python程序时，并不一定如你所愿。

​		例如，要使用Python进行一些计算密集型的工作。这里使用一个简单的数据分解操作代理执行：

~~~python
def factorize(number):
    for i in range(1, number + 1):
        if number % i == 0:
            yield i
~~~

​		分解一组连续的数字需要相当长的时间：

```python
import time


def factorize(number):
    for i in range(1, number + 1):
        if number % i == 0:
            yield i


numbers = [2139079, 1214759, 1516637, 1852285]
start = time.time()
for number in numbers:
    list(factorize(number))
end = time.time()
delta = end - start
print(f'Took {delta:.3f} seconds')
>>>
Took 0.555 seconds
```

​		使用多线程来完成这个计算在其他语言是有意义的，因为可以利用计算机的所有CPU内核。这里用Python试试。定义一个Python线程来执行与之前相同的计算：

```python
from threading import Thread
class FactorizeThread(Thread):
    def __init__(self, number):
        super().__init__()
        self.number = number
    def run(self):
        self.factors = list(factorize(self.number))
```

​	然后，我启动一个线程来并行分解每个数字:

```python
start = time.time()
threads = []
numbers = [2139079, 1214759, 1516637, 1852285]
for number in numbers:
    thread = FactorizeThread(number)
    thread.start()
    threads.append(thread)
```

​	最后，我等待所有线程完成:

```python
import time


def factorize(number):
    for i in range(1, number + 1):
        if number % i == 0:
            yield i


from threading import Thread


class FactorizeThread(Thread):
    def __init__(self, number):
        super().__init__()
        self.number = number

    def run(self):
        self.factors = list(factorize(self.number))


start = time.time()
threads = []
numbers = [2139079, 1214759, 1516637, 1852285]
for number in numbers:
    thread = FactorizeThread(number)
    thread.start()
    threads.append(thread)
for thread in threads:
    thread.join()
end = time.time()
delta = end - start
print(f'Took {delta:.3f} seconds')
>>>
Took 0.480 seconds
```

​		令人惊讶的是，这比串行运行中运行factorize话费的时间并不少多少。对于每个数字一个线程，由于创建线程和协调线程的开销，可能并不会像其他语言那样提高四倍的速率。可能希望在用来运行此代码的双核机器上只有2倍的速度。但是，当需要使用多个cpu时，这些线程的性能不会更好。这演示了GIL(例如，锁争用和调度开销)对在标准CPython解释器中运行的程序的影响。

​		有些方法可以让CPython使用多个核从而大幅度提高运行效率，但他们不能与标准的Thread类一起工作(参见第64条)。既然有这些限制，为什么Python还要支持多线程呢？有两个很重要的原因。

​		第一、多线程让程序很容易在同一时间看上去并行工作。同时处理多项任务是很难自己做到的(参见第56条)。有了多线程，就可以让Python并发运行函数。这是可行的，因为CPython确保了Python执行的线程之间一定程度的公平性，即使GIL，每次只有一个线程取得进展。

​		第二、是为了处理I/O阻塞，当Python执行某些类型的系统操作时，阻塞I/O会发生。

​		Python程序使用系统调用来完成计算机的操作系统与外部环境进行交互。阻塞I/O包括读取和写入文件、与网络交互、与显示器等设备通信等。线程将程序与操作系统响应请求所花费的时间隔离开来，从而帮助处理阻塞I/O。

​		例如，假设要通过串口向远程控制的直升机发送一个信号。将使用一个缓慢的系统调用作为这个活动的代理。这个函数要求操作系统阻塞0.1秒，然后将控制放回给程序，这类似于同步串行端口发生的情况：

~~~python
import select
import socket
def slow_systemcall():
    select.select([socket.socket()], [], [], 0.1)
~~~

​		串行运行这个系统调用需要线性增加的时间:

```python
import select
import socket
def slow_systemcall():
    select.select([socket.socket()], [], [], 0.1)

start = time.time()
for _ in range(5):
    slow_systemcall()
end = time.time()
delta = end - start
print(f'Took {delta:.3f} seconds')
>>>
Took 0.502 seconds
```

​		这样做的问题是，当slow_systemcall函数正在运行时，程序不能取得任何进展。程序执行的主线程被阻塞在select系统调用上。这种情况在实践中是非常可怕的。当向计算机发送信号时，需要能够计算出它的下一步行动；否则，它会崩溃。当发现需要同时执行阻塞I/O和计算时，就应该考虑将系统调用转移到线程中。

​		在这里，在单独的线程中运行多个slow_systemcall函数的调用。这将允许与多个串行端口(和直升机)在同一时间，同时离开主线程做任何需要的计算:

```python
start = time.time()
threads = []
for _ in range(5):
    thread = Thread(target=slow_systemcall)
thread.start()
threads.append(thread)
```

​		随着线程开始，这里做了一些工作来计算下一个直升机移动之前等待系统调用线程完成:

```
def compute_helicopter_location(index):
    ...
for i in range(5):
    compute_helicopter_location(i)
for thread in threads:
    thread.join()
end = time.time()
delta = end - start
print(f'Took {delta:.3f} seconds')
>>>
Took 0.108 seconds
```

​		**并行时间比串行时间小~5倍。这表明所有的系统调用都将从多个Python线程并行运行，即使它们受到GIL的限制。GIL阻止我的Python代码并行运行，但是它对系统调用没有影响。这是因为Python线程在进行系统调用之前释放GIL，并在系统调用完成后重新获取GIL。**

​		除了使用线程之外，还有许多其他方法来处理阻塞I/O，比如asyncio内置模块，这些替代方法有重要的好处。但是这些选项可能需要在重构代码以适应不同的执行模型时进行额外的工作(参见第60条和第62条)。使用线程是并行执行阻塞I/O的最简单方法，同时对程序进行最小的更改。

**要点**

* 由于全局解释器锁(GIL)， Python线程不能在多个CPU内核上并行运行
* 尽管有GIL, Python线程仍然是有用的，因为它们提供了一种简单的方法，似乎可以同时做多个事情
* 使用Python线程并行进行多个系统调用。这允许您在进行计算的同时进行阻塞I/O 

## 第54条 使用lock防止线程中的数据竞争

​		在学习了全局解释器锁(GIL)之后(参见第53条)，许多新的Python程序员认为他们可以完全放弃在他们的代码中使用互斥锁(也称为互斥锁)。如果GIL已经在阻止Python线程在多个CPU内核上并行运行，那么它还必须充当程序数据结构的锁，对吗?对列表和字典等类型的一些测试甚至可能显示这一假设似乎成立。

​		但要注意，事实并非如此。GIL不会保护你的。尽管一次只有一个Python线程运行，但线程对数据结构的操作可以在Python解释器中的任何两个字节码指令之间中断。如果同时从多个线程访问相同的对象，这是危险的。由于这些中断，数据结构的不变量实际上随时都可能被违反，使程序处于损坏状态。

​		例如，假设想编写一个并行计算许多事情的程序，比如从整个传感器网络中采样光级。如果想要确定一段时间内轻样本的总数，可以用一个新类来聚合它们：

​		假设每个传感器都有自己的工作线程，因为从传感器读取数据需要阻塞I/O。在每个传感器测量之后，工作线程将计数器增加到期望的最大读数:

​		在这里，为每个传感器并行运行一个工作线程，并等待它们完成它们的读数:

```python
class Counter:
    def __init__(self):
        self.count = 0

    def increment(self, offset):
        self.count += offset

def worker(sensor_index, how_many, counter):
    for _ in range(how_many):
        # Read from the sensor
        ...
        counter.increment(1)

from threading import Thread
how_many = 10**5
counter = Counter()
threads = []
for i in range(5):
    thread = Thread(target=worker,
                    args=(i, how_many, counter))
    threads.append(thread)
    thread.start()
for thread in threads:
    thread.join()
expected = how_many * 5
found = counter.count
print(f'Counter should be {expected}, got {found}')
>>>
Counter should be 500000, got 415471
```

​		这看起来很简单，结果也应该很明显，但结果却大相径庭!这里发生了什么?这么简单的事情怎么会出这么大的问题，尤其是在一次只能运行一个Python解释器线程的情况下?

​		Python解释器强制执行所有线程之间的公平性，以确保它们得到大致相同的处理时间。为此，Python在线程运行时暂停一个线程，并依次恢复另一个线程。问题是不知道Python什么时候会挂起线程。线程甚至可以在看似原子操作的过程中中途暂停。这就是本案的情况。

​		Counter对象的increment方法体看起来很简单，从工作线程的角度来看，相当于下面的语句:

~~~python
counter.count += 1
~~~

​		但是对象属性上使用的+=操作符实际上指示Python在后台执行三个独立的操作。上面的语句相当于:

~~~python
value = getattr(counter, 'count')
result = value + 1
setattr(counter, 'count', result)
~~~

​		递增计数器的Python线程可以挂起在上述任意两个操作之间。如果操作的交错方式导致将旧版本的值赋给计数器，那么这就有问题了。以下是两个线程(A和B)之间糟糕交互的例子:

```python
# Running in Thread A
value_a = getattr(counter, 'count')
# Context switch to Thread B
value_b = getattr(counter, 'count')
result_b = value_b + 1
setattr(counter, 'count', result_b)
# Context switch back to Thread A
result_a = value_a + 1
setattr(counter, 'count', result_a)
```

​		线程B在线程A完全完成之前中断了它。线程B运行并结束，但是线程A在执行过程中恢复，覆盖了线程B的计数器增量的所有进程。这正是上面光传感器的例子中所发生的。

​		为了防止类似的数据竞争和其他形式的数据结构损坏，Python在线程内置模块中包含了一组健壮的工具。其中最简单也是最有用的是Lock类，这是一个互斥锁(互斥锁)。

​		通过使用锁，可以让Counter类保护其当前值不受多个线程的同时访问。每次只有一个线程能够获得锁。在这里，使用一个with语句来获取和释放锁; 这使得当锁被持有时，更容易看到哪个代码正在执行(参见第66条):

```python
from threading import Lock
class LockingCounter:
    def __init__(self):
        self.lock = Lock()
        self.count = 0
    def increment(self, offset):
        with self.lock:
            self.count += offset
```

​		现在，像以前一样运行工作线程，但是使用一个LockingCounter

```python
from threading import Lock
class LockingCounter:
    def __init__(self):
        self.lock = Lock()
        self.count = 0
    def increment(self, offset):
        with self.lock:
            self.count += offset

counter = LockingCounter()
for i in range(5):
    thread = Thread(target=worker,
                    args=(i, how_many, counter))
    threads.append(thread)
    thread.start()
for thread in threads:
    thread.join()
expected = how_many * 5
found = counter.count
print(f'Counter should be {expected}, got {found}')
>>>
Counter should be 500000, got 500000
```

​		结果正是我所期望的。lock解决了这个问题。

**要点**

* 即使Python有一个全局解释器锁，仍然要防止程序中线程之间的数据竞争
* 如果允许多个线程在没有互斥锁(互斥锁)的情况下修改相同的对象，程序将破坏它们的数据结构
* 使用threading内置模块中的Lock类在多个线程之间强制执行程序的不变

## 第55条 使用队列来协调线程之间的工作

​		同时做很多事情的Python程序通常需要协调它们的工作。对并发工作最有用的安排之一是功能管道。

​		管道的工作原理就像制造业中的装配线。管道有许多串行的阶段，每个阶段都有特定的功能。新的工作不断地被添加到管道的开始。这些函数可以并发操作，每个函数处理其阶段中的工作片段。随着每个功能的完成，工作将继续进行，直到没有剩下的阶段。这种方法特别适用于包含阻塞I/O或子进程活动的工作，这些活动可以很容易地使用Python并行化(参见第53条)。

​		例如，假设想建立一个系统，它将从我的数码相机中持续获取图像流，调整它们的大小，然后将它们添加到在线图片库中。这样一个程序可以分为一个管道的三个阶段。在第一阶段检索新的图像。下载的图像在第二阶段通过resize函数传递。调整大小后的图像将由上传功能在最后阶段使用。

​		假设已经编写了执行以下阶段的Python函数:下载、调整大小、上传。我如何组装一个管道来并发地完成工作?

~~~python
def download(item):
	...
def resize(item):
	...
def upload(item):
	...

~~~

​		需要的第一件事是在管道阶段之间传递工作的方法。可以将其建模为线程安全的生产者-消费者队列(参见第53条和第71条):

~~~python
from collections import deque
from threading import Lock


class MyQueue:
    def __init__(self):
        self.items = deque()
        self.lock = Lock()
~~~

​		生产者人也就是数码相机，把新图像添加到一堆待定物品的末尾:

```python
def put(self, item):
    with self.lock:
        self.items.append(item)
```

​		消费者是处理管道的第一阶段，它从挂起项的队列前面删除图像:

```python
def get(self):
    with self.lock:
        return self.items.popleft()
```

​		在这里，将管道的每个阶段表示为一个Python线程，该线程从一个队列中获取工作，在其中运行一个函数，并将结果放到另一个队列中。我还会跟踪工人检查新输入的次数以及它完成了多少工作:

```python
class Worker(Thread):
    def __init__(self, func, in_queue, out_queue):
        super().__init__()
        self.func = func
        self.in_queue = in_queue
        self.out_queue = out_queue
        self.polled_count = 0
        self.work_done = 0
```

​		最棘手的部分是，工作线程必须正确处理输入队列为空的情况，因为前一个阶段还没有完成它的工作。这发生在捕获下面的IndexError异常的地方。可以把这看作是流水线上的一个阻碍:

```python
class Worker(Thread):
    def __init__(self, func, in_queue, out_queue):
        super().__init__()
        self.func = func
        self.in_queue = in_queue
        self.out_queue = out_queue
        self.polled_count = 0
        self.work_done = 0

    def run(self):
        while True:
            self.polled_count += 1
            try:
                item = self.in_queue.get()
            except IndexError:
                time.sleep(0.01)  # No work to do
            else:
                result = self.func(item)
                self.out_queue.put(result)
                self.work_done += 1
```

​		现在，可以通过为它们的协调点和相应的工作线程创建队列来将这三个阶段连接在一起:

```python
download_queue = MyQueue()
resize_queue = MyQueue()
upload_queue = MyQueue()
done_queue = MyQueue()
threads = [
    Worker(download, download_queue, resize_queue),
    Worker(resize, resize_queue, upload_queue),
    Worker(upload, upload_queue, done_queue),
        ]
```

​		可以启动线程，然后将一堆工作注入管道的第一阶段。在这里，使用一个普通对象实例作为下载函数所需的真实数据的代理:

```python
for thread in threads:
    thread.start()
for _ in range(1000):
    download_queue.put(object())
```

​		现在，等待所有的项目被管道处理，并结束在done_queue:

```python
while len(done_queue.items) < 1000:
    # Do something useful while waiting
    ...
```

​		这可以正常运行，但是有一个有趣的副作用，即线程轮询它们的输入队列以获取新工作。棘手的部分是，在run方法中捕获IndexError异常，执行了很多次:

```python
import time
from functools import wraps

from collections import deque
from threading import Lock
from threading import Thread


def download(item):
    ...


def resize(item):
    ...


def upload(item):
    ...


class MyQueue:
    def __init__(self):
        self.items = deque()
        self.lock = Lock()

    def put(self, item):
        with self.lock:
            self.items.append(item)

    def get(self):
        with self.lock:
            return self.items.popleft()


class Worker(Thread):
    def __init__(self, func, in_queue, out_queue):
        super().__init__()
        self.func = func
        self.in_queue = in_queue
        self.out_queue = out_queue
        self.polled_count = 0
        self.work_done = 0

    def run(self):
        while True:
            self.polled_count += 1
            try:
                item = self.in_queue.get()
            except IndexError:
                time.sleep(0.01)  # No work to do
            else:
                result = self.func(item)
                self.out_queue.put(result)
                self.work_done += 1


download_queue = MyQueue()
resize_queue = MyQueue()
upload_queue = MyQueue()
done_queue = MyQueue()
threads = [
    Worker(download, download_queue, resize_queue),
    Worker(resize, resize_queue, upload_queue),
    Worker(upload, upload_queue, done_queue),
]

for thread in threads:
    thread.start()
for _ in range(1000):
    download_queue.put(object())
while len(done_queue.items) < 1000:
    # Do something useful while waiting
    ...

processed = len(done_queue.items)
polled = sum(t.polled_count for t in threads)
print(f'Processed {processed} items after '
      f'polling {polled} times')
>>>
Processed 1000 items after polling 3012 times
```

​		当worker函数以各自的速度变化时，早期阶段可以阻止后期阶段的进展，从而备份管道。这将导致后面的阶段挨饿，并在一个紧密循环中不断检查它们的输入队列以获取新工作。结果是，工作线程浪费了CPU时间，不做任何有用的事情;他们不断地引发和捕获IndexError异常。

​		但这只是这个实现问题的开始。还有三个问题也应该避免。首先，确定所有的输入工作都已完成，需要在done_queue上再进行一次繁忙的等待。其次，在Worker中，run方法将在其繁忙循环中永远执行。没有明显的方法来通知工作线程是时候退出了。

​		第三，也是最糟糕的是，管道中的备份可能会任意地导致程序崩溃。如果第一阶段进展较快，而第二阶段进展缓慢，则第一阶段与第二阶段连接的队列规模将不断增大。第二阶段将无法跟上。如果有足够的时间和输入数据，程序最终会耗尽内存并死亡。

​		这里的教训不是管道是糟糕的;而是很难自己构建一个好的生产者-消费者队列。所以为什么还要尝试呢?

**排队救援**

​		Queue内置模块中的Queue类提供了解决上述问题所需的所有功能。

​		Queue通过使get方法块直到新数据可用来消除工作者中的忙碌等待。例如，这里我启动了一个线程，在队列上等待一些输入数据:

```python
from queue import Queue
my_queue = Queue()
def consumer():
    print('Consumer waiting')
	my_queue.get() # Runs after put() below
print('Consumer done')
thread = Thread(target=consumer)
thread.start()
```

​		即使线程先运行，它也不会结束，直到一个条目被放到Queue实例中，并且get方法有东西要返回:

```python
from queue import Queue
my_queue = Queue()
def consumer():
    print('Consumer waiting')
	my_queue.get() # Runs after put() below
print('Consumer done')
thread = Thread(target=consumer)
thread.start()
print('Producer putting')
my_queue.put(object()) # Runs before get() above
print('Producer done')
thread.join()
>>>
Consumer done
Consumer waitingProducer putting
Producer done
```

​		为了解决管道备份问题，Queue类允许指定两个阶段之间允许的最大暂挂工作量。

​		这个缓冲区大小导致在队列已经满时调用put来阻塞。例如，这里我定义了一个线程，在消费一个队列之前等待一段时间:

```python
def consumer():
    time.sleep(0.1)  # Wait
    my_queue.get()  # Runs second
    print('Consumer got 1')
    my_queue.get()  # Runs fourth
    print('Consumer got 2')
    print('Consumer done')


thread = Thread(target=consumer)
thread.start()
```

​		等待应该允许生产者线程在消费者线程调用get之前将两个对象放到队列中。但是队列大小是其中之一。这意味着在第二次put调用停止阻塞并将第二项添加到队列中之前，生产者将不得不等待消费线程调用get至少一次:

```python
my_queue = Queue(1)  # Buffer size of 1


def consumer():
    time.sleep(0.1)  # Wait
    my_queue.get()  # Runs second
    print('Consumer got 1')
    my_queue.get()  # Runs fourth
    print('Consumer got 2')
    print('Consumer done')


thread = Thread(target=consumer)
thread.start()
my_queue.put(object()) # Runs first
print('Producer put 1')
my_queue.put(object()) # Runs third
print('Producer put 2')
print('Producer done')
thread.join()
>>>
Producer put 1
Consumer got 1
Producer put 2
Producer done
Consumer got 2
Consumer done
```

​		Queue类还可以使用task_done方法跟踪工作进度。这允许等待阶段的输入队列耗尽，并消除了轮询管道的最后一个阶段的需要(与上面的done_queue一样)。例如，这里定义了一个消费者线程，当它完成一个项目的工作时调用task_done:

```python
in_queue = Queue()
def consumer():
    print('Consumer waiting')
    work = in_queue.get() # Runs second
    print('Consumer working')
    # Doing work
    ...
    print('Consumer done')
    in_queue.task_done()  # Runs third

thread = Thread(target=consumer)
thread.start()
```

​		现在，生产者代码不必加入消费者线程或轮询。生产者可以通过调用Queue实例上的join来等待in_queue完成。即使它是空的，in_queue也不会是可连接的，直到对所有已排队的项调用task_done之后:

```python
in_queue = Queue()


def consumer():
    print('Consumer waiting')
    work = in_queue.get()  # Runs second
    print('Consumer working')
    # Doing work
    ...
    print('Consumer done')
    in_queue.task_done()  # Runs third


thread = Thread(target=consumer)
thread.start()
print('Producer putting')
in_queue.put(object())  # Runs first
print('Producer waiting')
in_queue.join()  # Runs fourth
print('Producer done')
thread.join()
>>>
Consumer waiting
Producer putting
Producer waiting
Consumer working
Consumer done
Producer done
```

​		可以把所有这些行为放到一个Queue子类中，这个子类还会告诉工作线程它应该在什么时候停止处理。在这里，定义了一个close方法，它向队列中添加了一个特殊的哨兵项，表明在它之后将没有更多的输入项:

​		然后，为队列定义一个迭代器，用于查找这个特殊对象，并在找到它时停止迭代。这个--iter--方法也会在适当的时候调用task_done，来跟踪队列上的工作进度

```python
class ClosableQueue(Queue):
    SENTINEL = object()
    def close(self):
        self.put(self.SENTINEL)

    def __iter__(self):
        while True:
            item = self.get()
            try:
                if item is self.SENTINEL:
                    return  # Cause the thread to exit
                yield item
            finally:
                self.task_done()
```

​		现在，可以重新定义工作线程，以依赖于ClosableQueue类的行为。当for循环耗尽时，线程将退出:

```python
class StoppableWorker(Thread):
    def __init__(self, func, in_queue, out_queue):
        super().__init__()
        self.func = func
        self.in_queue = in_queue
        self.out_queue = out_queue
    def run(self):
        for item in self.in_queue:
            result = self.func(item)
            self.out_queue.put(result)
```

​		使用新的工作线程类重新创建了一组工作线程:

```python

class ClosableQueue(Queue):
    SENTINEL = object()

    def close(self):
        self.put(self.SENTINEL)

    def __iter__(self):
        while True:
            item = self.get()
            try:
                if item is self.SENTINEL:
                    return  # Cause the thread to exit
                yield item
            finally:
                self.task_done()


class StoppableWorker(Thread):
    def __init__(self, func, in_queue, out_queue):
        super().__init__()
        self.func = func
        self.in_queue = in_queue
        self.out_queue = out_queue

    def run(self):
        for item in self.in_queue:
            result = self.func(item)
            self.out_queue.put(result)


download_queue = ClosableQueue()
resize_queue = ClosableQueue()
upload_queue = ClosableQueue()
done_queue = ClosableQueue()
threads = [
    StoppableWorker(download, download_queue, resize_queue),
    StoppableWorker(resize, resize_queue, upload_queue),
    StoppableWorker(upload, upload_queue, done_queue),
]
```

​		在像之前一样运行工作线程之后，也通过关闭第一阶段的输入队列来发送停止信号:

```python
for thread in threads:
    thread.start()
for _ in range(1000):
    download_queue.put(object())
download_queue.close()
```

​		最后，通过加入连接各个阶段的队列来等待工作完成。每当一个阶段完成时，通过关闭它的输入队列来通知下一个阶段停止。最后，done_queue包含了所有的输出对象，如预期的那样:

```python
def download(item):
    ...


def resize(item):
    ...


def upload(item):
    ...

class ClosableQueue(Queue):
    SENTINEL = object()

    def close(self):
        self.put(self.SENTINEL)

    def __iter__(self):
        while True:
            item = self.get()
            try:
                if item is self.SENTINEL:
                    return  # Cause the thread to exit
                yield item
            finally:
                self.task_done()


class StoppableWorker(Thread):
    def __init__(self, func, in_queue, out_queue):
        super().__init__()
        self.func = func
        self.in_queue = in_queue
        self.out_queue = out_queue

    def run(self):
        for item in self.in_queue:
            result = self.func(item)
            self.out_queue.put(result)


download_queue = ClosableQueue()
resize_queue = ClosableQueue()
upload_queue = ClosableQueue()
done_queue = ClosableQueue()
threads = [
    StoppableWorker(download, download_queue, resize_queue),
    StoppableWorker(resize, resize_queue, upload_queue),
    StoppableWorker(upload, upload_queue, done_queue),
]
for thread in threads:
    thread.start()
for _ in range(1000):
    download_queue.put(object())
download_queue.close()
download_queue.join()
resize_queue.close()
resize_queue.join()
upload_queue.close()
upload_queue.join()
print(done_queue.qsize(), 'items finished')
for thread in threads:
    thread.join()
>>>
1000 items finished
```

​		这种方法可以扩展为在每个阶段使用多个工作线程，这可以增加I/O并行性，并显著提高这种类型的程序的速度。为此，首先定义一些启动和停止多个线程的辅助函数。stop_threads的工作方式是在每个使用线程的输入队列上调用一次close，这确保了所有的worker干净地退出:

```python
def start_threads(count, *args):
    threads = [StoppableWorker(*args) for _ in range(count)]
    for thread in threads:
        thread.start()
    return threads


def stop_threads(closable_queue, threads):
    for _ in threads:
        closable_queue.close()
    closable_queue.join()
    for thread in threads:
        thread.join()
```

​		然后，像之前一样将这些片段连接在一起，将要处理的对象放在管道的顶部，在此过程中加入队列和线程，最后使用结果:

```python
def start_threads(count, *args):
    threads = [StoppableWorker(*args) for _ in range(count)]
    for thread in threads:
        thread.start()
    return threads


def stop_threads(closable_queue, threads):
    for _ in threads:
        closable_queue.close()
    closable_queue.join()
    for thread in threads:
        thread.join()


download_queue = ClosableQueue()
resize_queue = ClosableQueue()
upload_queue = ClosableQueue()
done_queue = ClosableQueue()
download_threads = start_threads(
    3, download, download_queue, resize_queue)
resize_threads = start_threads(
    4, resize, resize_queue, upload_queue)
upload_threads = start_threads(
    5, upload, upload_queue, done_queue)
for _ in range(1000):
    download_queue.put(object())
stop_threads(download_queue, download_threads)
stop_threads(resize_queue, resize_threads)
stop_threads(upload_queue, upload_threads)
print(done_queue.qsize(), 'items finished')
>>>
1000 items finished
```

​		尽管Queue在这种线性管道的情况下工作得很好，但是还有许多其他情况需要考虑更好的工具(参见第60条)。

**要点**

* 管道是组织使用多个Python线程并发运行的工作序列(特别是I/O绑定程序)的好方法
* 在构建并发管道时要注意许多问题:忙则等待，如何告诉工人停止，以及潜在的内存爆炸
* Queue类具有构建健壮管道所需的所有工具:阻塞操作、缓冲区大小和join

## 第56条 知道如何识别何时并发是必要的

​		不可避免的是，随着程序范围的扩大，它也会变得更加复杂。以保持清晰性、可测试性和效率的方式处理扩展需求是编程中最困难的部分之一。也许最难处理的变化类型是从单线程程序转移到需要多行并发执行的程序。

​		让我用一个例子来说明可能遇到的这个问题。假设想实现Conway的Game of Life，这是有限状态自动机的一个经典例子。游戏规则很简单:有一个任意大小的二维网格。网格中的每个单元格要么是活的，要么是空的:

> ALIVE = '*'
> EMPTY = '-'

​		游戏每次只进行一次。每只扁虱，每个细胞都要计算相邻的8个细胞中还有多少存活。根据邻近细胞的数量，一个细胞决定它是继续生存、死亡还是再生。(我将在下文解释具体规则。)这是一个5 × 5 Game of Life网格的例子，四代后时间向右移动:

| 0     | 1     | 2     | 3     | 4     |
| ----- | ----- | ----- | ----- | ----- |
| -*--- | --*-- | --**- | --*-- | ----- |
| --**- | --**- | -*--- | -*--- | -**-- |
| ---*- | --**- | --**- | --*-- | ----- |
| ----- | ----- | ----- | ----- | ----- |

​		可以用一个简单的容器类表示每个单元格的状态。类必须有方法，允许获得和设置任何坐标的值。越界的坐标应该环绕，使网格像一个无限循环空间:

```python
ALIVE = '*'
EMPTY = '-'


class Grid:
    def __init__(self, height, width):
        self.height = height
        self.width = width
        self.rows = []
        for _ in range(self.height):
            self.rows.append([EMPTY] * self.width)

    def get(self, y, x):
        return self.rows[y % self.height][x % self.width]

    def set(self, y, x, state):
        self.rows[y % self.height][x % self.width] = state

    def __str__(self):
        ...
```

​		为了查看这个类的实际操作，可以创建一个Grid实例，并将其初始状态设置为一个称为滑翔机的经典形状:

```python
ALIVE = '*'
EMPTY = '-'


class Grid:
    def __init__(self, height, width):
        self.height = height
        self.width = width
        self.rows = []
        for _ in range(self.height):
            self.rows.append([EMPTY] * self.width)

    def get(self, y, x):
        return self.rows[y % self.height][x % self.width]

    def set(self, y, x, state):
        self.rows[y % self.height][x % self.width] = state

    def __str__(self):
        output = ''
        for row in self.rows:
            for cell in row:
                output += cell
            output += '\n'
        return output


grid = Grid(5, 9)
grid.set(0, 3, ALIVE)
grid.set(1, 4, ALIVE)
grid.set(2, 2, ALIVE)
grid.set(2, 3, ALIVE)
grid.set(2, 4, ALIVE)
print(grid)
>>>
---*-----
----*----
--***----
---------
---------
```

​		现在，需要一种方法来检索邻近细胞的状态。可以使用一个辅助函数来实现这一点，它查询网格并返回居住邻居的计数。为了减少耦合，使用一个简单的函数作为get参数，而不是传入整个Grid实例(参见第38条):

```python
def count_neighbors(y, x, get):
    n_ = get(y - 1, x + 0) # North
    ne = get(y - 1, x + 1) # Northeast
    e_ = get(y + 0, x + 1) # East
    se = get(y + 1, x + 1) # Southeast
    s_ = get(y + 1, x + 0) # South
    sw = get(y + 1, x - 1) # Southwest
    w_ = get(y + 0, x - 1) # West
    nw = get(y - 1, x - 1) # Northwest
    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]
    count = 0
    for state in neighbor_states:
        if state == ALIVE:
            count += 1
    return count
alive = {(9, 5), (9, 6)}
seen = set()
def fake_get(y, x):
    position = (y, x)
    seen.add(position)
    return ALIVE if position in alive else EMPTY

count = count_neighbors(10, 5, fake_get)
expected_seen = {
    (9, 5),  (9, 6),  (10, 6), (11, 6),
    (11, 5), (11, 4), (10, 4), (9, 4)
}
print(seen)
>>>
{(10, 4), (9, 6), (11, 6), (9, 5), (10, 6), (11, 5), (11, 4), (9, 4)}
```

​		现在，根据游戏的三个规则来定义Conway的生命游戏的简单逻辑:如果一个细胞的邻居少于两个就死亡，如果一个细胞的邻居多于三个就死亡，如果一个空的细胞恰好有三个邻居就活:

```python
def game_logic(state, neighbors):
    if state == ALIVE:
        if neighbors < 2:
            return EMPTY  # Die: Too few
        elif neighbors > 3:
            return EMPTY  # Die: Too many
    else:
        if neighbors == 3:
            return ALIVE  # Regenerate
    return state
```

​		可以在另一个转换单元格状态的函数中连接count_neighbors和game_logic。这个函数将在每一代中被调用，以找出一个单元格的当前状态，检查它周围的相邻单元格，确定它的下一个状态应该是什么，并相应地更新结果网格。同样，使用一个函数接口来设置，而不是传入Grid实例，以使代码更解耦:

```python
def step_cell(y, x, get, set):
    state = get(y, x)
    neighbors = count_neighbors(y, x, get)
    next_state = game_logic(state, neighbors)
    set(y, x, next_state)
    
alive = {(10, 5), (9, 5), (9, 6)}
new_state = None
def fake_get(y, x):
    return ALIVE if (y, x) in alive else EMPTY

def fake_set(y, x, state):
    global new_state
    new_state = state

# Stay alive
step_cell(10, 5, fake_get, fake_set)
print(new_state)
# Stay dead
alive.remove((10, 5))
step_cell(10, 5, fake_get, fake_set)
print(new_state)
# Regenerate
alive.add((10, 6))
step_cell(10, 5, fake_get, fake_set)
print(new_state)
>>>
*
-
*
```

​		最后，可以定义一个函数，将整个网格的单元格向前推进一步，然后返回一个包含下一代状态的新网格。这里重要的细节是，需要所有依赖函数来调用上一代Grid实例上的get方法，并调用下一代Grid实例上的set方法。这是确保所有单元格都能同步移动的方法，这也是游戏运作的重要部分。这很容易实现，因为使用了get和set函数接口，而不是传递Grid实例:

```python
def simulate(grid):
    next_grid = Grid(grid.height, grid.width)
    for y in range(grid.height):
        for x in range(grid.width):
            step_cell(y, x, grid.get, next_grid.set)
    return next_grid
```

​		现在，可以让grid每一代向前发展。根据game_logic函数的简单规则，可以看到滑翔机是如何在网格上向下和向右移动的:

```python
def simulate(grid):
    next_grid = Grid(grid.height, grid.width)
    for y in range(grid.height):
        for x in range(grid.width):
            step_cell(y, x, grid.get, next_grid.set)
    return next_grid


class ColumnPrinter:
    def __init__(self):
        self.columns = []

    def append(self, data):
        self.columns.append(data)

    def __str__(self):
        row_count = 1
        for data in self.columns:
            row_count = max(
                row_count, len(data.splitlines()) + 1)

        rows = [''] * row_count
        for j in range(row_count):
            for i, data in enumerate(self.columns):
                line = data.splitlines()[max(0, j - 1)]
                if j == 0:
                    padding = ' ' * (len(line) // 2)
                    rows[j] += padding + str(i) + padding
                else:
                    rows[j] += line

                if (i + 1) < len(self.columns):
                    rows[j] += ' | '

        return '\n'.join(rows)

grid = Grid(5, 9)
grid.set(0, 3, ALIVE)
grid.set(1, 4, ALIVE)
grid.set(2, 2, ALIVE)
grid.set(2, 3, ALIVE)
grid.set(2, 4, ALIVE)

columns = ColumnPrinter()
for i in range(5):
    columns.append(str(grid))
grid = simulate(grid)
print(columns)
>>>
    0     |     1     |     2     |     3     |     4    
---*----- | ---*----- | ---*----- | ---*----- | ---*-----
----*---- | ----*---- | ----*---- | ----*---- | ----*----
--***---- | --***---- | --***---- | --***---- | --***----
--------- | --------- | --------- | --------- | ---------
--------- | --------- | --------- | --------- | ---------
```

​		对于可以在一台机器上的一个线程中运行的程序来说，这非常有效。但是，假设程序的需求发生了变化——正如我上面提到的那样——现在我需要从game_logic函数中执行一些I/O(例如，使用一个套接字)。例如，如果我试图构建一个大型多人在线游戏，其中状态转换由网格状态和通过Internet与其他玩家的通信组合决定，那么这可能是必需的。

```python
def game_logic(state, neighbors):
    ...
    # Do some blocking input/output in here:
    data = my_socket.recv(100)
    ...
```

​		这种方法的问题是它会减慢整个程序的速度。如果所需的I / O延迟100毫秒(即,一个相当好的越野、往返延迟在互联网上),然后有45网格中的细胞,每一代将最低的4.5秒的评价,因为每个细胞是串行处理的模拟功能。这样做太慢了，会让游戏无法玩。它的伸缩性也很差:如果后来想将网格扩展到10,000个单元，将需要超过15分钟来评估每一代。

​		解决方案是并行执行I/O，因此无论网格有多大，每次生成大约需要100毫秒。为每个工作单元(在本例中是单元格)生成并发执行行的过程称为扇出。等待所有这些并发的工作单元完成，然后才能进入协调流程的下一个阶段(在本例中是生成)，这称为扇入。

​	Python提供了许多内置工具来实现扇形输出和扇形输入，并进行了各种权衡。应该了解每种方法的优缺点，并根据具体情况选择最适合这项工作的工具。请看下面的项目，以了解基于这个生命游戏示例程序的详细信息(参见第57、第58、第60条).

**要点**

* 当一个程序的范围和复杂性增加时，它通常需要多个并发执行行
* 最常见的并发协调类型是扇出(生成新的并发单元)和扇入(等待现有并发单元完成)
* Python有许多不同的方式来实现扇出和扇入

## 第57条 避免为按需扇出创建新的线程实例

​		线程是在Python中执行并行I/O首选工具(参见第53条)。然而，当试图将它们用于分散到许多并发执行行时，它们有显著的缺点。为了演示这一点，我将继续前面的Game of Life例子(参见第56条)。使用线程来解决在game_logic函数中执行I/O所导致的延时问题。首先，线程需要使用锁进行协调，以确保正确维护数据结构中的假设。可以创建一个Grid类的子类，添加锁定行为，以便一个实例可以被多个线程同时调用：

~~~python
from threading import Lock

ALIVE = '*'
EMPTY = '-'


class Grid:
    def __init__(self, height, width):
        self.height = height
        self.width = width
        self.rows = []
        for _ in range(self.height):
            self.rows.append([EMPTY] * self.width)

    def get(self, y, x):
        return self.rows[y % self.height][x % self.width]

    def set(self, y, x, state):
        self.rows[y % self.height][x % self.width] = state

    def __str__(self):
        output = ''
        for row in self.rows:
            for cell in row:
                output += cell
            output += '\n'
        return output


class LockingGrid(Grid):
    def __init__(self, height, width):
        super().__init__(height, width)
        self.lock = Lock()

    def __str__(self):
        with self.lock:
            return super().__str__()

    def get(self, y, x):
        with self.lock:
            return super().get(y, x)

    def set(self, y, x, state):
        with self.lock:
            return super().set(y, x, state)
~~~

​		然后，可以重新实现模拟函数，通过为每个对step_cell的调用创建一个线程来展开。这些线程将并行运行，不必等待彼此的I/O。然后，可以通过等待所有线程完成，然后转移到下一代:

~~~python
from threading import Thread

def count_neighbors(y, x, get):
    n_ = get(y - 1, x + 0)  # North
    ne = get(y - 1, x + 1)  # Northeast
    e_ = get(y + 0, x + 1)  # East
    se = get(y + 1, x + 1)  # Southeast
    s_ = get(y + 1, x + 0)  # South
    sw = get(y + 1, x - 1)  # Southwest
    w_ = get(y + 0, x - 1)  # West
    nw = get(y - 1, x - 1)  # Northwest
    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]
    count = 0
    for state in neighbor_states:
        if state == ALIVE:
            count += 1
    return count

def game_logic(state, neighbors):
    # Do some blocking input/output in here:
    data = my_socket.recv(100)

def game_logic(state, neighbors):
    if state == ALIVE:
        if neighbors < 2:
            return EMPTY     # Die: Too few
        elif neighbors > 3:
            return EMPTY     # Die: Too many
    else:
        if neighbors == 3:
            return ALIVE     # Regenerate
    return state

def step_cell(y, x, get, set):
    state = get(y, x)
    neighbors = count_neighbors(y, x, get)
    next_state = game_logic(state, neighbors)
    set(y, x, next_state)

def simulate_threaded(grid):
    next_grid = LockingGrid(grid.height, grid.width)

    threads = []
    for y in range(grid.height):
        for x in range(grid.width):
            args = (y, x, grid.get, next_grid.set)
            thread = Thread(target=step_cell, args=args)
            thread.start()  # Fan out
            threads.append(thread)

    for thread in threads:
        thread.join()       # Fan in

    return next_grid
~~~

​		可以像之前那样使用step_cell相同的实现结构和相同的驱动代码运行代码，只改变了在实现LockingGrid和simulate_threading两处的代码:

~~~python
class ColumnPrinter:
    def __init__(self):
        self.columns = []

    def append(self, data):
        self.columns.append(data)

    def __str__(self):
        row_count = 1
        for data in self.columns:
            row_count = max(
                row_count, len(data.splitlines()) + 1)

        rows = [''] * row_count
        for j in range(row_count):
            for i, data in enumerate(self.columns):
                line = data.splitlines()[max(0, j - 1)]
                if j == 0:
                    padding = ' ' * (len(line) // 2)
                    rows[j] += padding + str(i) + padding
                else:
                    rows[j] += line

                if (i + 1) < len(self.columns):
                    rows[j] += ' | '

        return '\n'.join(rows)

grid = LockingGrid(5, 9)            # Changed
grid.set(0, 3, ALIVE)
grid.set(1, 4, ALIVE)
grid.set(2, 2, ALIVE)
grid.set(2, 3, ALIVE)
grid.set(2, 4, ALIVE)

columns = ColumnPrinter()
for i in range(5):
    columns.append(str(grid))
    grid = simulate_threaded(grid)  # Changed

print(columns)
>>>
    0     |     1     |     2     |     3     |     4    
---*----- | --------- | --------- | --------- | ---------
----*---- | --*-*---- | ----*---- | ---*----- | ----*----
--***---- | ---**---- | --*-*---- | ----**--- | -----*---
--------- | ---*----- | ---**---- | ---**---- | ---***---
--------- | --------- | --------- | --------- | ---------
~~~

​		这将会像预期的那样工作，并且I/O现在在线程之间并行化了。然而，这段代码有三个大的问题：

* 线程实例需要特殊的工具来相互安全协作(参见第54条)。这使得使用线程的代码比以前的过程式单线程代码更难推理。随着时间的推移，这种复杂性使得线程代码更加难以扩展和维护
* 线程需要大量内存—每个执行线程大约需要8mb内存。在许多计算机上，对于我在本例中需要的45个线程来说，内存的大小并不重要。但如果游戏网格必须增长到1万个单元格，就需要创建那么多线程，而这些线程甚至无法装入机器的内存。这样的话为每个并发活动运行一个线程是行不通的
* 启动线程代价很高，而且由于线程之间的上下文切换，线程在运行时会产生负面的性能影响。在这种情况下，所有线程都会在游戏的每一代中启动和停止，这将带来很高的开销，并将增加延迟，超过预期的100毫秒的I/O时间

​		如果出现错误，这段代码也很难调试。例如，假设game_logic函数引发了异常，这可能是由于I/O的脆弱性特征：

~~~python
def game_logic(state, neighbors):
    ...
    raise OSError('Problem with I/O')
    ...
~~~

​		可以通过运行一个指向该函数的Thread实例并从程序中重定向sys.stderr输出到内存缓冲区StringIO：

~~~python
import contextlib
import io
fake_stderr = io.StringIO()
with contextlib.redirect_stderr(fake_stderr):
    thread = Thread(target=game_logic, args=(ALIVE, 3))
    thread.start()
    thread.join()
print(fake_stderr.getvalue())
>>>
Exception in thread Thread-1:
Traceback (most recent call last):
  File "D:\python38\lib\threading.py", line 932, in _bootstrap_inner
    self.run()
  File "D:\python38\lib\threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "E:/pycharm_pro/EffectivePythonCode/item40/3.py", line 137, in game_logic
    raise OSError('Problem with I/O')
OSError: Problem with I/O
~~~

​		像预期的那样抛出了OSError异常，但无论如何创建Thread并调用是不受影响的。这怎么可能呢？原因是Thread类将独立捕获目标函数引发的异常，然后将他们的回溯写到sys.stderr。此类异常永远不会重新抛给线程的最初调用者。

​		考虑到所有这些问题，如果需要不断创建和完成新的并发函数，那么线程显然不是解决方案。Python提供了更适合的其他解决方案(参见第58条、第59条、第60条)

**要点**

* 线程有很多缺点:如果需要大量线程，那么启动和运行线程的成本很高，每个线程都需要大量内存，并且它们需要Lock实例等特殊工具进行协调
* 线程没有提供内置的方法来在启动线程或等待线程结束的代码中引发异常，这使得它们难以调试

## 第58条 学会正确地重构代码，以便用Queue做并发

​		在前面的项目中(参见第57条)，讲解了所有使用线程解决并行I/O问题的确定，这也在之前的the Game of Life游戏中有体现(参见第56条)。

​		下一步尝试的方法是使用Queue内置模块中的Queue类来实现线程管道(参见第55条)。

​		这里是一种通用的方法:比起在每代Game of Life中为每个单元格创建一个线程，可以预先创建固定数量的工作线程，并让它们根据需要进行并行I/O。这将使资源使用处于控制之下，并消除频繁启动新线程的开销。

​		为此，需要两个ClosableQueue实例用于与执行game_logic函数的工作线程通信：

~~~python
from queue import Queue

class ClosableQueue(Queue):
    SENTINEL = object()

    def close(self):
        self.put(self.SENTINEL)

    def __iter__(self):
        while True:
            item = self.get()
            try:
                if item is self.SENTINEL:
                    return  # Cause the thread to exit
                yield item
            finally:
                self.task_done()

in_queue = ClosableQueue()
out_queue = ClosableQueue()
~~~

​		可以启动多个线程来使用in_queue中的条目，通过调用game_logic来处理它们，并将结果放到out_queue上。这些线程将并发运行，允许并行I/O，并减少每次生成的延迟:

```python
ALIVE = '*'
EMPTY = '-'
from queue import Queue


class ClosableQueue(Queue):
    SENTINEL = object()

    def close(self):
        self.put(self.SENTINEL)

    def __iter__(self):
        while True:
            item = self.get()
            try:
                if item is self.SENTINEL:
                    return  # Cause the thread to exit
                yield item
            finally:
                self.task_done()


in_queue = ClosableQueue()
out_queue = ClosableQueue()

from threading import Thread


class StoppableWorker(Thread):
    def __init__(self, func, in_queue, out_queue, **kwargs):
        super().__init__(**kwargs)
        self.func = func
        self.in_queue = in_queue
        self.out_queue = out_queue

    def run(self):
        for item in self.in_queue:
            result = self.func(item)
            self.out_queue.put(result)


def game_logic(state, neighbors):
    # Do some blocking input/output in here:
    # data = my_socket.recv(1000)
    ...


def game_logic(state, neighbors):
    if state == ALIVE:
        if neighbors < 2:
            return EMPTY  # Die: Too few
        elif neighbors > 3:
            return EMPTY  # Die: Too many
    else:
        if neighbors == 3:
            return ALIVE  # Regenerate
    return state


def game_logic_thread(item):
    y, x, state, neighbors = item
    try:
        next_state = game_logic(state, neighbors)
    except Exception as e:
        next_state = e
    return (y, x, next_state)


# Start the threads upfront
threads = []
for _ in range(5):
    thread = StoppableWorker(
        game_logic_thread, in_queue, out_queue)
    thread.start()
    threads.append(thread)
```

​		现在，可以重新定义模拟函数来与这些队列交互，以请求状态转换决策并接收相应的响应。向in_queue中添加项目会导致扇出，从out_queue中消费项目直到它为空会导致扇入:

~~~python
class SimulationError(Exception):
    pass

class Grid:
    def __init__(self, height, width):
        self.height = height
        self.width = width
        self.rows = []
        for _ in range(self.height):
            self.rows.append([EMPTY] * self.width)

    def get(self, y, x):
        return self.rows[y % self.height][x % self.width]

    def set(self, y, x, state):
        self.rows[y % self.height][x % self.width] = state

    def __str__(self):
        output = ''
        for row in self.rows:
            for cell in row:
                output += cell
            output += '\n'
        return output

def count_neighbors(y, x, get):
    n_ = get(y - 1, x + 0)  # North
    ne = get(y - 1, x + 1)  # Northeast
    e_ = get(y + 0, x + 1)  # East
    se = get(y + 1, x + 1)  # Southeast
    s_ = get(y + 1, x + 0)  # South
    sw = get(y + 1, x - 1)  # Southwest
    w_ = get(y + 0, x - 1)  # West
    nw = get(y - 1, x - 1)  # Northwest
    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]
    count = 0
    for state in neighbor_states:
        if state == ALIVE:
            count += 1
    return count

def simulate_pipeline(grid, in_queue, out_queue):
    for y in range(grid.height):
        for x in range(grid.width):
            state = grid.get(y, x)
            neighbors = count_neighbors(y, x, grid.get)
            in_queue.put((y, x, state, neighbors))  # Fan out

    in_queue.join()
    out_queue.close()

    next_grid = Grid(grid.height, grid.width)
    for item in out_queue:                          # Fan in
        y, x, next_state = item
        if isinstance(next_state, Exception):
            raise SimulationError(y, x) from next_state
        next_grid.set(y, x, next_state)

    return next_grid

~~~

​	Gird.get和Gird.set的调用都发生在这个新的simulate_pipeline函数中，这意味着可以使用Grid的单线程实现，而不是需要Lock实例进行同步的实现。这段代码也比前一项中使用的Thread方法更容易调试。如果在game_logic函数中执行I/O时发生异常，它将被捕获，传播到out_queue，然后在主线程中重新引发:

```python
try:
    def game_logic(state, neighbors):
        raise OSError('Problem with I/O in game_logic')
    
    simulate_pipeline(Grid(1, 1), in_queue, out_queue)
except:
    logging.exception('Expected')
else:
    assert False
```

​		可以通过在循环中调用simulate_pipeline来驱动这个多线程管道的重复生成:

```python
# Clear the sentinel object from the out queue
for _ in out_queue:
    pass

# Restore the working version of this function
def game_logic(state, neighbors):
    if state == ALIVE:
        if neighbors < 2:
            return EMPTY     # Die: Too few
        elif neighbors > 3:
            return EMPTY     # Die: Too many
    else:
        if neighbors == 3:
            return ALIVE     # Regenerate
    return state

class ColumnPrinter:
    def __init__(self):
        self.columns = []

    def append(self, data):
        self.columns.append(data)

    def __str__(self):
        row_count = 1
        for data in self.columns:
            row_count = max(
                row_count, len(data.splitlines()) + 1)

        rows = [''] * row_count
        for j in range(row_count):
            for i, data in enumerate(self.columns):
                line = data.splitlines()[max(0, j - 1)]
                if j == 0:
                    padding = ' ' * (len(line) // 2)
                    rows[j] += padding + str(i) + padding
                else:
                    rows[j] += line

                if (i + 1) < len(self.columns):
                    rows[j] += ' | '

        return '\n'.join(rows)

grid = Grid(5, 9)
grid.set(0, 3, ALIVE)
grid.set(1, 4, ALIVE)
grid.set(2, 2, ALIVE)
grid.set(2, 3, ALIVE)
grid.set(2, 4, ALIVE)

columns = ColumnPrinter()
for i in range(5):
    columns.append(str(grid))
    grid = simulate_pipeline(grid, in_queue, out_queue)

print(columns)

for thread in threads:
    in_queue.close()
for thread in threads:
    thread.join()
>>>
    0     |     1     |     2     |     3     |     4    
---*----- | --------- | --------- | --------- | ---------
----*---- | --*-*---- | ----*---- | ---*----- | ----*----
--***---- | ---**---- | --*-*---- | ----**--- | -----*---
--------- | ---*----- | ---**---- | ---**---- | ---***---
--------- | --------- | --------- | --------- | ---------
```

​		结果和之前一样。虽然已经解决了内存爆炸问题，启动成本，以及单独使用线程的调试问题，但仍然存在许多问题:

* simulate_pipeline函数比前一项中的simulate_threading方法更难理解
* 为了使代码更容易阅读，ClosableQueue和stopableworker需要额外的支持类，但代价是增加了复杂性。
* 必须根据对工作负载的期望预先指定潜在的并行度——运行game_logic_thread的线程数，而不是让系统根据需要自动地扩大并行度
* 为了启用调试，必须在工作线程中手动捕获异常，在Queue上传播它们，然后在主线程中重新引发它们

​		然而，如果需求再次改变，这段代码的最大问题就很明显了。想象一下，之后除了game_logic需要的I/O外，还需要在count_neighbors函数中执行I/O:

```python
def count_neighbors(y, x, get):
    # Do some blocking input/output in here:
    data = my_socket.recv(100)
```

​		为了使此过程可并行化，需要向在线程中运行count_neighbors的管道中添加另一个阶段。需要确保异常在工作线程和主线程之间正确传播。需要使用一个网格类锁以确保安全工作线程之间的同步(参见第54条和第57条):

```python
def count_neighbors(y, x, get):
    n_ = get(y - 1, x + 0)  # North
    ne = get(y - 1, x + 1)  # Northeast
    e_ = get(y + 0, x + 1)  # East
    se = get(y + 1, x + 1)  # Southeast
    s_ = get(y + 1, x + 0)  # South
    sw = get(y + 1, x - 1)  # Southwest
    w_ = get(y + 0, x - 1)  # West
    nw = get(y - 1, x - 1)  # Northwest
    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]
    count = 0
    for state in neighbor_states:
        if state == ALIVE:
            count += 1
    return count

def count_neighbors_thread(item):
    y, x, state, get = item
    try:
        neighbors = count_neighbors(y, x, get)
    except Exception as e:
        neighbors = e
    return (y, x, state, neighbors)

def game_logic_thread(item):
    y, x, state, neighbors = item
    if isinstance(neighbors, Exception):
        next_state = neighbors
    else:
        try:
            next_state = game_logic(state, neighbors)
        except Exception as e:
            next_state = e
    return (y, x, next_state)

from threading import Lock

class LockingGrid(Grid):
    def __init__(self, height, width):
        super().__init__(height, width)
        self.lock = Lock()

    def __str__(self):
        with self.lock:
            return super().__str__()

    def get(self, y, x):
        with self.lock:
            return super().get(y, x)

    def set(self, y, x, state):
        with self.lock:
            return super().set(y, x, state)
```

​		必须为count_neighbors_thread工作者和相应的Thread实例创建另一组Queue实例：

```python
in_queue = ClosableQueue()
logic_queue = ClosableQueue()
out_queue = ClosableQueue()

threads = []

for _ in range(5):
    thread = StoppableWorker(
        count_neighbors_thread, in_queue, logic_queue)
    thread.start()
    threads.append(thread)

for _ in range(5):
    thread = StoppableWorker(
        game_logic_thread, logic_queue, out_queue)
    thread.start()
    threads.append(thread)
```

​		最后，需要更新simulate_pipeline，以协调管道中的多个阶段，并确保工作扇出和返回正确:

```python
def simulate_phased_pipeline(
        grid, in_queue, logic_queue, out_queue):
    for y in range(grid.height):
        for x in range(grid.width):
            state = grid.get(y, x)
            item = (y, x, state, grid.get)
            in_queue.put(item)          # Fan out

    in_queue.join()
    logic_queue.join()                  # Pipeline sequencing
    out_queue.close()

    next_grid = LockingGrid(grid.height, grid.width)
    for item in out_queue:              # Fan in
        y, x, next_state = item
        if isinstance(next_state, Exception):
            raise SimulationError(y, x) from next_state
        next_grid.set(y, x, next_state)

    return next_grid
```

​		有了这些更新的实现，现在可以运行多相管道端到端:

```python
grid = LockingGrid(5, 9)
grid.set(0, 3, ALIVE)
grid.set(1, 4, ALIVE)
grid.set(2, 2, ALIVE)
grid.set(2, 3, ALIVE)
grid.set(2, 4, ALIVE)

columns = ColumnPrinter()
for i in range(5):
    columns.append(str(grid))
    grid = simulate_phased_pipeline(
        grid, in_queue, logic_queue, out_queue)

print(columns)

for thread in threads:
    in_queue.close()
for thread in threads:
    logic_queue.close()
for thread in threads:
    thread.join()
>>>
0 | 1 | 2 | 3 | 4
---*----- | --------- | --------- | --------- | ---------
----*---- | --*-*---- | ----*---- | ---*----- | ----*----
--***---- | ---**---- | --*-*---- | ----**--- | -----*---
--------- | ---*----- | ---**---- | ---**---- | ---***---
--------- | --------- | --------- | --------- | ---------
```

​		同样，这可以按预期工作，但它需要大量的更改和样板文件。这里的要点是，Queue确实可以解决扇出和扇入问题，但开销非常高。尽管使用队列是一个更好的方法比使用线程的实例,它仍然是比不上一些Python提供的其他工具(参见第59条和第60条)	

**要点**

* 使用具有固定工作线程数量的Queue实例提高了使用线程的扇出和扇入的可伸缩性
* 重构现有代码以使用Queue需要大量的工作，特别是在需要管道的多个阶段时
* 与其他内置Python特性和模块提供的替代方法相比，使用Queue从根本上限制了程序可以利用的I/O并行性总量

## 第59条 如果必须用线程做并发，那就考虑通过ThreadPoolExecutor实现

​		Python包含内置模块concurrent.futures，提供ThreadPoolExecutor类。它结合了最好的Thread(参见第57条)和Queue(参见第58条)的方法来解决生命游戏的并行I/O问题(参见第56条):

```python
from time import sleep
from threading import Lock

ALIVE = '*'
EMPTY = '-'


class Grid:
    def __init__(self, height, width):
        self.height = height
        self.width = width
        self.rows = []
        for _ in range(self.height):
            self.rows.append([EMPTY] * self.width)

    def get(self, y, x):
        return self.rows[y % self.height][x % self.width]

    def set(self, y, x, state):
        self.rows[y % self.height][x % self.width] = state

    def __str__(self):
        output = ''
        for row in self.rows:
            for cell in row:
                output += cell
            output += '\n'
        return output


class LockingGrid(Grid):
    def __init__(self, height, width):
        super().__init__(height, width)
        self.lock = Lock()

    def __str__(self):
        with self.lock:
            return super().__str__()

    def get(self, y, x):
        with self.lock:
            return super().get(y, x)

    def set(self, y, x, state):
        with self.lock:
            return super().set(y, x, state)


def count_neighbors(y, x, get):
    n_ = get(y - 1, x + 0)  # North
    ne = get(y - 1, x + 1)  # Northeast
    e_ = get(y + 0, x + 1)  # East
    se = get(y + 1, x + 1)  # Southeast
    s_ = get(y + 1, x + 0)  # South
    sw = get(y + 1, x - 1)  # Southwest
    w_ = get(y + 0, x - 1)  # West
    nw = get(y - 1, x - 1)  # Northwest
    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]
    count = 0
    for state in neighbor_states:
        if state == ALIVE:
            count += 1
    return count


def game_logic(state, neighbors):
    # Do some blocking input/output in here:
    # data = my_socket.recv(100)
    sleep(3)


def game_logic(state, neighbors):
    if state == ALIVE:
        if neighbors < 2:
            return EMPTY  # Die: Too few
        elif neighbors > 3:
            return EMPTY  # Die: Too many
    else:
        if neighbors == 3:
            return ALIVE  # Regenerate
    return state


def step_cell(y, x, get, set):
    state = get(y, x)
    neighbors = count_neighbors(y, x, get)
    next_state = game_logic(state, neighbors)
    set(y, x, next_state)
```

​			不需要为每个Grid方块启动一个新的Thread实例，而是可以通过向执行程序提交一个函数，该执行程序将在单独的线程中运行。稍后，可以等待所有任务的结果，以便扇入:

```python
from concurrent.futures import ThreadPoolExecutor
def simulate_pool(pool, grid):
    next_grid = LockingGrid(grid.height, grid.width)

    futures = []
    for y in range(grid.height):
        for x in range(grid.width):
            args = (y, x, grid.get, next_grid.set)
            future = pool.submit(step_cell, *args)  # Fan out
            futures.append(future)

    for future in futures:
        future.result()                             # Fan in

    return next_grid
```

​		用于执行器的线程可以预先分配，这意味着不必在每次执行simulate_pool时支付启动成本。还可以指定池中使用的最大线程数——使用max_workers参数——以防止通过Thread解决并行I/O问题方案导致的内存膨胀问题:

```python
class ColumnPrinter:
    def __init__(self):
        self.columns = []

    def append(self, data):
        self.columns.append(data)

    def __str__(self):
        row_count = 1
        for data in self.columns:
            row_count = max(
                row_count, len(data.splitlines()) + 1)

        rows = [''] * row_count
        for j in range(row_count):
            for i, data in enumerate(self.columns):
                line = data.splitlines()[max(0, j - 1)]
                if j == 0:
                    padding = ' ' * (len(line) // 2)
                    rows[j] += padding + str(i) + padding
                else:
                    rows[j] += line

                if (i + 1) < len(self.columns):
                    rows[j] += ' | '

        return '\n'.join(rows)

grid = LockingGrid(5, 9)
grid.set(0, 3, ALIVE)
grid.set(1, 4, ALIVE)
grid.set(2, 2, ALIVE)
grid.set(2, 3, ALIVE)
grid.set(2, 4, ALIVE)

columns = ColumnPrinter()
with ThreadPoolExecutor(max_workers=10) as pool:
    for i in range(5):
        columns.append(str(grid))
        grid = simulate_pool(pool, grid)

print(columns)
>>>
    0     |     1     |     2     |     3     |     4    
---*----- | --------- | --------- | --------- | ---------
----*---- | --*-*---- | ----*---- | ---*----- | ----*----
--***---- | ---**---- | --*-*---- | ----**--- | -----*---
--------- | ---*----- | ---**---- | ---**---- | ---***---
--------- | --------- | --------- | --------- | ---------
```

​		ThreadPoolExecutor类最棒的地方在于，当结果方法被提交方法返回的Future实例调用时，它会自动将异常传播回调用者:

```python
try:
    def game_logic(state, neighbors):
        raise OSError('Problem with I/O')
    
    with ThreadPoolExecutor(max_workers=10) as pool:
        task = pool.submit(game_logic, ALIVE, 3)
        task.result()
except:
    logging.exception('Expected')
else:
    assert False
    
>>>
Traceback ...
OSError: Problem with I/O
```

​		如果需要在game_logic之外为count_neighbors函数提供I/O并行性，则不需要对程序进行修改，因为ThreadPoolExecutor已经作为step_cell的一部分并发运行这些函数。如果需要的话，甚至可以通过使用相同的接口来实现CPU的并行性(参见第64条)。

​		然而，仍然存在的大问题是ThreadPoolExecutor提供的I/O并行量有限。即使使用max_workers参数为100，如果在网格中需要10,000多个需要同时I/O的单元格，这个解决方案仍然无法扩展。对于没有异步解决方案(例如，文件I/O)的情况，ThreadPoolExecutor是一个很好的选择，但在许多情况下，有更好的方法来最大化I/O并行性(参见第60条)。

**要点**

* ThreadPoolExecutor通过有限的重构实现了简单的I/O并行，轻松地避免了每次需要扇形并发时启动线程的成本
* 尽管ThreadPoolExecutor消除了直接使用线程可能带来的内存膨胀问题，但它也限制了I/O并行性，因为它要求预先指定max_workers

## 第60条 用协程实现高并发的I/O

​		之前的几节尝试着解决《Game of Life》例子中的并行I/O问题，并取得了不同程度的成功(参见第56条)。所有其他方法在处理数千个同时并发函数的能力上都有不足(参见第57条和第58条、第59条)。	

​		Python通过协程解决了高并发I/O的需求。协程让你在Python程序中拥有大量看起来同时存在的函数。它们是使用async和await关键字以及为生成器提供动力的相同基础设施实现的(参见第30条、第34条和第35条)。

​		启动协程的代价是一个函数调用。一旦协程被激活，它使用不到1kb的内存，直到耗尽为止。与线程一样，协程是独立的函数，可以使用其环境的输入并产生结果输出。不同之处在于协程会在每个await表达式处暂停，并在解决悬而未决的可等待对象后继续执行async函数(类似于生成器中的yield行为)。

​		许多单独的异步函数看起来都是同步运行的，模仿了Python线程的并发行为。然而，协程在完成这一任务时没有内存开销、启动和上下文切换开销，也没有线程所需的复杂锁定和同步代码。为协程提供动力的神奇机制是事件循环，它可以高效地执行高并发I/O，同时在适当编写的函数之间快速交错执行。

​		可以使用协程来实现《Game of Life》。目标是允许在game_logic函数中出现I/O，同时克服前面提到的线程和队列方法所带来的问题。为了做到这一点，首先通过使用async def而不是def来定义game_logic函数，从而表明它是一个协程。这将允许在I/O中使用await语法，比如从套接字异步读取:

```python
ALIVE = '*'
EMPTY = '-'

class Grid:
    def __init__(self, height, width):
        self.height = height
        self.width = width
        self.rows = []
        for _ in range(self.height):
            self.rows.append([EMPTY] * self.width)

    def get(self, y, x):
        return self.rows[y % self.height][x % self.width]

    def set(self, y, x, state):
        self.rows[y % self.height][x % self.width] = state

    def __str__(self):
        output = ''
        for row in self.rows:
            for cell in row:
                output += cell
            output += '\n'
        return output

def count_neighbors(y, x, get):
    n_ = get(y - 1, x + 0)  # North
    ne = get(y - 1, x + 1)  # Northeast
    e_ = get(y + 0, x + 1)  # East
    se = get(y + 1, x + 1)  # Southeast
    s_ = get(y + 1, x + 0)  # South
    sw = get(y + 1, x - 1)  # Southwest
    w_ = get(y + 0, x - 1)  # West
    nw = get(y - 1, x - 1)  # Northwest
    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]
    count = 0
    for state in neighbor_states:
        if state == ALIVE:
            count += 1
    return count

async def game_logic(state, neighbors):
    # Do some input/output in here:
    data = await my_socket.read(50)

async def game_logic(state, neighbors):
    if state == ALIVE:
        if neighbors < 2:
            return EMPTY     # Die: Too few
        elif neighbors > 3:
            return EMPTY     # Die: Too many
    else:
        if neighbors == 3:
            return ALIVE     # Regenerate
    return state
```

​		类似地，可以通过在其定义中添加async并使用await调用game_logic函数来将step_cell转换为协程:

~~~python
async def step_cell(y, x, get, set):
    state = get(y, x)
    neighbors = count_neighbors(y, x, get)
    next_state = await game_logic(state, neighbors)
    set(y, x, next_state)

~~~

​		模拟函数也需要成为一个协程：

~~~python
import asyncio

async def simulate(grid):
    next_grid = Grid(grid.height, grid.width)

    tasks = []
    for y in range(grid.height):
        for x in range(grid.width):
            task = step_cell(
                y, x, grid.get, next_grid.set)      # Fan out
            tasks.append(task)

    await asyncio.gather(*tasks)                    # Fan in

    return next_grid

~~~

​		模拟函数的协程版本需要一些解释:

* 调用step_cell不会立即运行该函数。相反，它返回一个协程实例，可以在以后与await表达式一起使用。这类似于使用yield的生成器函数在调用时返回一个生成器实例，而不是立即执行。像这样延迟执行就是导致扇出的机制
* 来自asyncio内置库的gather函数会导致扇入。gather上的await表达式指示事件循环并发运行step_cell协程，并在所有这些协程都完成后恢复模拟协程的执行
* Grid实例不需要锁，因为所有执行都发生在一个线程中。作为asyncio提供的事件循环的一部分，I/O被并行化

​		最后，我可以通过对原始示例的一行更改来驱动这段代码。这依赖于asyncio.run函数在事件循环中执行模拟协程并执行其相关的I/O:

```python
class ColumnPrinter:
    def __init__(self):
        self.columns = []

    def append(self, data):
        self.columns.append(data)

    def __str__(self):
        row_count = 1
        for data in self.columns:
            row_count = max(
                row_count, len(data.splitlines()) + 1)

        rows = [''] * row_count
        for j in range(row_count):
            for i, data in enumerate(self.columns):
                line = data.splitlines()[max(0, j - 1)]
                if j == 0:
                    padding = ' ' * (len(line) // 2)
                    rows[j] += padding + str(i) + padding
                else:
                    rows[j] += line

                if (i + 1) < len(self.columns):
                    rows[j] += ' | '

        return '\n'.join(rows)

logging.getLogger().setLevel(logging.ERROR)

grid = Grid(5, 9)
grid.set(0, 3, ALIVE)
grid.set(1, 4, ALIVE)
grid.set(2, 2, ALIVE)
grid.set(2, 3, ALIVE)
grid.set(2, 4, ALIVE)

columns = ColumnPrinter()
for i in range(5):
    columns.append(str(grid))
    grid = asyncio.run(simulate(grid))   # Run the event loop

print(columns)

logging.getLogger().setLevel(logging.DEBUG)
>>>
0 | 1 | 2 | 3 | 4
---*----- | --------- | --------- | --------- | ---------
----*---- | --*-*---- | ----*---- | ---*----- | ----*----
--***---- | ---**---- | --*-*---- | ----**--- | -----*---
--------- | ---*----- | ---**---- | ---**---- | ---***---
--------- | --------- | --------- | --------- | ---------
```

​		结果和以前一样。与线程相关的所有开销都被消除了。尽管Queue和ThreadPoolExecutor方法在异常处理方面受到限制——仅仅是跨线程边界重新引发异常——但通过协程，实际上可以使用交互式调试器逐行遍历代码(参见第80条):

```python
try:
    async def game_logic(state, neighbors):
        raise OSError('Problem with I/O')
    
    logging.getLogger().setLevel(logging.ERROR)
    
    asyncio.run(game_logic(ALIVE, 3))
    
    logging.getLogger().setLevel(logging.DEBUG)
except:
    logging.exception('Expected')
else:
    assert False
```

​		以后,如果需求改变并且需要count_neighbors做一些I/O操作,可以通过在现有函数前添加 async和await关键词就可以实现，而不是采用Thread和Queue对整个结构进行重构(参见第61条):

```python
async def count_neighbors(y, x, get):
    n_ = get(y - 1, x + 0)  # North
    ne = get(y - 1, x + 1)  # Northeast
    e_ = get(y + 0, x + 1)  # East
    se = get(y + 1, x + 1)  # Southeast
    s_ = get(y + 1, x + 0)  # South
    sw = get(y + 1, x - 1)  # Southwest
    w_ = get(y + 0, x - 1)  # West
    nw = get(y - 1, x - 1)  # Northwest
    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]
    count = 0
    for state in neighbor_states:
        if state == ALIVE:
            count += 1
    return count

async def step_cell(y, x, get, set):
    state = get(y, x)
    neighbors = await count_neighbors(y, x, get)
    next_state = await game_logic(state, neighbors)
    set(y, x, next_state)

async def game_logic(state, neighbors):
    if state == ALIVE:
        if neighbors < 2:
            return EMPTY     # Die: Too few
        elif neighbors > 3:
            return EMPTY     # Die: Too many
    else:
        if neighbors == 3:
            return ALIVE     # Regenerate
    return state

logging.getLogger().setLevel(logging.ERROR)

grid = Grid(5, 9)
grid.set(0, 3, ALIVE)
grid.set(1, 4, ALIVE)
grid.set(2, 2, ALIVE)
grid.set(2, 3, ALIVE)
grid.set(2, 4, ALIVE)

columns = ColumnPrinter()
for i in range(5):
    columns.append(str(grid))
    grid = asyncio.run(simulate(grid))

print(columns)

logging.getLogger().setLevel(logging.DEBUG)
>>>
0 | 1 | 2 | 3 | 4
---*----- | --------- | --------- | --------- | ---------
----*---- | --*-*---- | ----*---- | ---*----- | ----*----
--***---- | ---**---- | --*-*---- | ----**--- | -----*---
--------- | ---*----- | ---**---- | ---**---- | ---***---
--------- | --------- | --------- | --------- | ---------
```

​		协程的美妙之处在于，它们将代码的外部环境指令(即I/O)与实现我们想实现的方法(即事件循环)解耦。它们让你专注于你想要做的事情的逻辑，而不是浪费时间试图弄清楚你要如何同时完成你的目标。

**要点**

* 使用async关键字定义的函数称为协程。调用者可以使用await关键字接收依赖协程的结果
* 协程提供了一种有效的方法，似乎可以同时运行数万个函数
* 协程可以使用扇出和扇入来并行化I/O，同时还克服了与在线程中执行I/O相关的所有问题

## 第61条 学会用asyncio改写那些通过线程实现的I/O

​		一旦了解了协程的优势(参见第60条)，用协程对已有的代码进行重构就会凸显其巨大优势。幸运的是，Python对异步执行的支持被很好地集成到了该语言中。这使得执行线程化、阻塞I/O的代码转移到协程和异步I/O变得很简单。

​		例如，有一个基于TCP的服务器用来进行猜数字游戏。服务器采用猜测者猜测的范围转化为最大和最小值两个参数。然后，服务器根据客户机的请求返回该范围内的猜测整数值。最后，服务器从客户机收集报告，说明这些数字与客户机的秘密数字是更近(更热)还是更远(更冷)。

​		构建这种类型的客户端/服务器系统最常见的方法是使用阻塞I/O和线程(参见第53条)。为此，需要一个可以管理消息发送和接收的辅助类。就目的而言，发送或接收的每一行表示一个要处理的命令:

```python
class EOFError(Exception):
    pass


class ConnectionBase:
    def __init__(self, connection):
        self.connection = connection
        self.file = connection.makefile('rb')

    def send(self, command):
        line = command + '\n'
        data = line.encode()
        self.connection.send(data)

    def receive(self):
        line = self.file.readline()
        if not line:
            raise EOFError('Connection closed')
        return line[:-1].decode()
```

​		服务器通过一个每次处理一个链接并维护一个客户端对话状态的类来实现：

```python
import random

WARMER = 'Warmer'
COLDER = 'Colder'
UNSURE = 'Unsure'
CORRECT = 'Correct'


class UnknownCommandError(Exception):
    pass


class Session(ConnectionBase):
    def __init__(self, *args):
        super().__init__(*args)
        self._clear_state(None, None)

    def _clear_state(self, lower, upper):
        self.lower = lower
        self.upper = upper
        self.secret = None
        self.guesses = []
```

​		它有一个主要方法来处理从客户端传入的命令，并根据需要将他们分派给具体的方法。注意，这里使用赋值表达式(参见第10条)以保持代码的间接性：

```python
def loop(self):
    while command := self.receive():
        parts = command.split(' ')
        if parts[0] == 'PARAMS':
            self.set_params(parts)
        elif parts[0] == 'NUMBER':
            self.send_number()
        elif parts[0] == 'REPORT':
            self.receive_report(parts)
        else:
            raise UnknownCommandError(command)
```

​		第一个命令设置服务器试图猜测的数字的下界和上界:

```python
def set_params(self, parts):
    assert len(parts) == 3
    lower = int(parts[1])
    upper = int(parts[2])
    self._clear_state(lower, upper)
```

​		第二个命令根据存储在客户端Session实例中的前一个状态进行新的猜测。具体来说，这段代码确保服务器永远不会尝试对每个参数赋值多次猜测相同的数字:

```python
def next_guess(self):
    if self.secret is not None:
        return self.secret

    while True:
        guess = random.randint(self.lower, self.upper)
        if guess not in self.guesses:
            return guess

def send_number(self):
    guess = self.next_guess()
    self.guesses.append(guess)
    self.send(format(guess))
```

​		第三个命令从客户端接收猜测是更热还是更冷的决定，并相应地更新Session状态：

```python
def receive_report(self, parts):
    assert len(parts) == 2
    decision = parts[1]

    last = self.guesses[-1]
    if decision == CORRECT:
        self.secret = last

    print(f'Server: {last} is {decision}')
```

​		客户端也是使用有状态类实现的:

```python
import contextlib
import math

class Client(ConnectionBase):
    def __init__(self, *args):
        super().__init__(*args)
        self._clear_state()

    def _clear_state(self):
        self.secret = None
        self.last_distance = None
```

​		每个猜谜游戏的参数设置都要使用with语句，以确保该命令语句在管理服务器侧的正确性(参见第66条和第63条)。这个方法将第一个命令发送到服务器:

```python
@contextlib.contextmanager
def session(self, lower, upper, secret):
    print(f'Guess a number between {lower} and {upper}!'
          f' Shhhhh, it\'s {secret}.')
    self.secret = secret
    self.send(f'PARAMS {lower} {upper}')
    try:
        yield
    finally:
        self._clear_state()
        self.send('PARAMS 0 -1')
```

​		使用另一种实现第二个命令的方法盲从服务器请求新的猜测：

```python
def request_numbers(self, count):
    for _ in range(count):
        self.send('NUMBER')
        data = self.receive()
        yield int(data)
        if self.last_distance == 0:
            return
```

​		服务器的每次猜测是否比上次的更热或更冷，都将使用最后方法中的第三个命令来报告:

```python
def report_outcome(self, number):
    new_distance = math.fabs(number - self.secret)
    decision = UNSURE

    if new_distance == 0:
        decision = CORRECT
    elif self.last_distance is None:
        pass
    elif new_distance < self.last_distance:
        decision = WARMER
    elif new_distance > self.last_distance:
        decision = COLDER

    self.last_distance = new_distance

    self.send(f'REPORT {decision}')
    return decision
```

​		可以通过启用一个线程监听一个套接字，并产生额外的线程来处理新的连接来运行服务器:

```python
import socket
from threading import Thread

def handle_connection(connection):
    with connection:
        session = Session(connection)
        try:
            session.loop()
        except EOFError:
            pass

def run_server(address):
    with socket.socket() as listener:
        # Allow the port to be reused
        listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        listener.bind(address)
        listener.listen()
        while True:
            connection, _ = listener.accept()
            thread = Thread(target=handle_connection,
                            args=(connection,),
                            daemon=True)
            thread.start()
```

​		客户机在主线程中运行，并将猜测游戏的结果返回给调用者。这段代码显式地练习了各种Python语言特性(for循环，语句，生成器，推导式)，所以下面我可以展示如何使用协程来移植这些特性:

```python
def run_client(address):
    with socket.create_connection(address) as connection:
        client = Client(connection)

        with client.session(1, 5, 3):
            results = [(x, client.report_outcome(x))
                       for x in client.request_numbers(5)]

        with client.session(10, 15, 12):
            for number in client.request_numbers(5):
                outcome = client.report_outcome(number)
                results.append((number, outcome))

    return results
```

​		最后，可以把所有这些拼接在一起，并确认它能按预期工作:

```python
import contextlib
import math
import random
import socket
from threading import Thread


class EOFError(Exception):
    pass


class ConnectionBase:
    def __init__(self, connection):
        self.connection = connection
        self.file = connection.makefile('rb')

    def send(self, command):
        line = command + '\n'
        data = line.encode()
        self.connection.send(data)

    def receive(self):
        line = self.file.readline()
        if not line:
            raise EOFError('Connection closed')
        return line[:-1].decode()


WARMER = 'Warmer'
COLDER = 'Colder'
UNSURE = 'Unsure'
CORRECT = 'Correct'


class UnknownCommandError(Exception):
    pass


class Session(ConnectionBase):
    def __init__(self, *args):
        super().__init__(*args)
        self._clear_state(None, None)

    def _clear_state(self, lower, upper):
        self.lower = lower
        self.upper = upper
        self.secret = None
        self.guesses = []

    def loop(self):
        while command := self.receive():
            parts = command.split(' ')
            if parts[0] == 'PARAMS':
                self.set_params(parts)
            elif parts[0] == 'NUMBER':
                self.send_number()
            elif parts[0] == 'REPORT':
                self.receive_report(parts)
            else:
                raise UnknownCommandError(command)

    def set_params(self, parts):
        assert len(parts) == 3
        lower = int(parts[1])
        upper = int(parts[2])
        self._clear_state(lower, upper)

    def next_guess(self):
        if self.secret is not None:
            return self.secret

        while True:
            guess = random.randint(self.lower, self.upper)
            if guess not in self.guesses:
                return guess

    def send_number(self):
        guess = self.next_guess()
        self.guesses.append(guess)
        self.send(format(guess))

    def receive_report(self, parts):
        assert len(parts) == 2
        decision = parts[1]

        last = self.guesses[-1]
        if decision == CORRECT:
            self.secret = last

        print(f'Server: {last} is {decision}')


class Client(ConnectionBase):
    def __init__(self, *args):
        super().__init__(*args)
        self._clear_state()

    def _clear_state(self):
        self.secret = None
        self.last_distance = None

    @contextlib.contextmanager
    def session(self, lower, upper, secret):
        print(f'Guess a number between {lower} and {upper}!'
              f' Shhhhh, it\'s {secret}.')
        self.secret = secret
        self.send(f'PARAMS {lower} {upper}')
        try:
            yield
        finally:
            self._clear_state()
            self.send('PARAMS 0 -1')

    def request_numbers(self, count):
        for _ in range(count):
            self.send('NUMBER')
            data = self.receive()
            yield int(data)
            if self.last_distance == 0:
                return

    def report_outcome(self, number):
        new_distance = math.fabs(number - self.secret)
        decision = UNSURE

        if new_distance == 0:
            decision = CORRECT
        elif self.last_distance is None:
            pass
        elif new_distance < self.last_distance:
            decision = WARMER
        elif new_distance > self.last_distance:
            decision = COLDER

        self.last_distance = new_distance

        self.send(f'REPORT {decision}')
        return decision


def handle_connection(connection):
    with connection:
        session = Session(connection)
        try:
            session.loop()
        except EOFError:
            pass


def run_server(address):
    with socket.socket() as listener:
        # Allow the port to be reused
        listener.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        listener.bind(address)
        listener.listen()
        while True:
            connection, _ = listener.accept()
            thread = Thread(target=handle_connection,
                            args=(connection,),
                            daemon=True)
            thread.start()


def run_client(address):
    with socket.create_connection(address) as connection:
        client = Client(connection)

        with client.session(1, 5, 3):
            results = [(x, client.report_outcome(x))
                       for x in client.request_numbers(5)]

        with client.session(10, 15, 12):
            for number in client.request_numbers(5):
                outcome = client.report_outcome(number)
                results.append((number, outcome))

    return results


def main():
    address = ('127.0.0.1', 1234)
    server_thread = Thread(
        target=run_server, args=(address,), daemon=True)
    server_thread.start()

    results = run_client(address)
    for number, outcome in results:
        print(f'Client: {number} is {outcome}')


main()
>>>
Guess a number between 1 and 5! Shhhhh, it's 3.
Server: 5 is Unsure
Server: 4 is Warmer
Server: 3 is Correct
Guess a number between 10 and 15! Shhhhh, it's 12.
Server: 14 is Unsure
Server: 11 is Warmer
Server: 15 is Colder
Server: 13 is Warmer
Server: 12 is Correct
Client: 5 is Unsure
Client: 4 is Warmer
Client: 3 is Correct
Client: 14 is Unsure
Client: 11 is Warmer
Client: 15 is Colder
Client: 13 is Warmer
Client: 12 is Correct
```

​		将这个示例转换为使用async、await和asyncio内置模块需要付出多少功夫呢?

​		首先，需要更新ConnectionBase类，以提供发送和接收的协程，而不是阻塞I/O方法。已经用# changed注释标记了每一行，以明确这个新例子和上面的代码之间的增量是什么:

```python
class AsyncConnectionBase:
    def __init__(self, reader, writer):             # Changed
        self.reader = reader                        # Changed
        self.writer = writer                        # Changed

    async def send(self, command):
        line = command + '\n'
        data = line.encode()
        self.writer.write(data)                     # Changed
        await self.writer.drain()                   # Changed

    async def receive(self):
        line = await self.reader.readline()         # Changed
        if not line:
            raise EOFError('Connection closed')
        return line[:-1].decode()
```

​		可以创建另一个有状态类来表示单个连接的会话状态。这里唯一的变化是类的名称和继承自AsyncConnectionBase而不是ConnectionBase:

```python
class AsyncSession(AsyncConnectionBase):            # Changed
    def __init__(self, *args):
        super().__init__(*args)
        self._clear_values(None, None)

    def _clear_values(self, lower, upper):
        self.lower = lower
        self.upper = upper
        self.secret = None
        self.guesses = []
```

​		服务器的命令处理循环的主要入口点只需要进行很小的更改就可以成为一个协程：

```python
async def loop(self):                           # Changed
    while command := await self.receive():      # Changed
        parts = command.split(' ')
        if parts[0] == 'PARAMS':
            self.set_params(parts)
        elif parts[0] == 'NUMBER':
            await self.send_number()            # Changed
        elif parts[0] == 'REPORT':
            self.receive_report(parts)
        else:
            raise UnknownCommandError(command)
```

​		处理第一个命令不需要做任何更改：

```python
def set_params(self, parts):
    assert len(parts) == 3
    lower = int(parts[1])
    upper = int(parts[2])
    self._clear_values(lower, upper)
```

​		第二个命令所需的惟一更改是，当猜测被传输到客户机时，允许使用异步I/O

```python
def next_guess(self):
    if self.secret is not None:
        return self.secret

    while True:
        guess = random.randint(self.lower, self.upper)
        if guess not in self.guesses:
            return guess

async def send_number(self):                    # Changed
    guess = self.next_guess()
    self.guesses.append(guess)
    await self.send(format(guess))              # Changed
```

​		第三个命令不需要修改:

```python
def receive_report(self, parts):
    assert len(parts) == 2
    decision = parts[1]

    last = self.guesses[-1]
    if decision == CORRECT:
        self.secret = last

    print(f'Server: {last} is {decision}')
```

​		类似地，客户端类需要重新实现从AsyncConnectionBase继承:

```python
class AsyncClient(AsyncConnectionBase):             # Changed
    def __init__(self, *args):
        super().__init__(*args)
        self._clear_state()

    def _clear_state(self):
        self.secret = None
        self.last_distance = None
```

​		客户端的第一个命令方法需要添加几个async和await关键字。它还需要使用contextlib内置模块中的asynccontextmanager助手函数:

```python
@contextlib.asynccontextmanager                 # Changed
async def session(self, lower, upper, secret):  # Changed
    print(f'Guess a number between {lower} and {upper}!'
          f' Shhhhh, it\'s {secret}.')
    self.secret = secret
    await self.send(f'PARAMS {lower} {upper}')  # Changed
    try:
        yield
    finally:
        self._clear_state()
        await self.send('PARAMS 0 -1')
```

​		第二个命令同样只需要在任何需要协程行为的地方添加async和await:

```python
async def request_numbers(self, count):         # Changed
    for _ in range(count):
        await self.send('NUMBER')               # Changed
        data = await self.receive()             # Changed
        yield int(data)
        if self.last_distance == 0:
            return
```

​		第三个命令只需要添加一个async和一个await关键字:

```python
async def report_outcome(self, number):         # Changed
    new_distance = math.fabs(number - self.secret)
    decision = UNSURE

    if new_distance == 0:
        decision = CORRECT
    elif self.last_distance is None:
        pass
    elif new_distance < self.last_distance:
        decision = WARMER
    elif new_distance > self.last_distance:
        decision = COLDER

    self.last_distance = new_distance

    await self.send(f'REPORT {decision}')       # Changed
    # Make it so the output printing is in
    # the same order as the threaded version.
    await asyncio.sleep(0.01)
    return decision
```

​		运行服务器的代码需要完全重新实现，以使用asyncio内置模块及其start_server函数:

```python
import asyncio

async def handle_async_connection(reader, writer):
    session = AsyncSession(reader, writer)
    try:
        await session.loop()
    except EOFError:
        pass

async def run_async_server(address):
    server = await asyncio.start_server(
        handle_async_connection, *address)
    async with server:
        await server.serve_forever()
```

​		启动游戏的run_client函数几乎每一行都需要更改。以前与阻塞套接字实例交互的任何代码都必须用类似功能的asyncio版本替换(下面用# New标记)。函数中需要与协程交互的所有其他行都需要适当地使用async和await关键字。如果忘记在必要的位置添加这些关键字之一，将在运行时引发异常。

```python
async def run_async_client(address):
    # Wait for the server to listen before trying to connect
    await asyncio.sleep(0.1)

    streams = await asyncio.open_connection(*address)   # New
    client = AsyncClient(*streams)                      # New

    async with client.session(1, 5, 3):
        results = [(x, await client.report_outcome(x))
                   async for x in client.request_numbers(5)]

    async with client.session(10, 15, 12):
        async for number in client.request_numbers(5):
            outcome = await client.report_outcome(number)
            results.append((number, outcome))

    _, writer = streams                                 # New
    writer.close()                                      # New
    await writer.wait_closed()                          # New

    return results
```

​		关于run_async_client最有趣的是，为了将这个函数移植到使用协程，不需要重新构造与AsyncClient交互的任何实质性部分。需要的每一种语言特性都有相应的异步版本，这使得迁移很容易完成。

​		不过，情况并不总是如此。目前还没有next和iter内置函数的异步版本(参见第31条);必须在--anext--和--aiter--方法上直接使用await。这里也没有异步版本的yield from(参见第33条)，这使得合成生成器变得更复杂。但是考虑到Python中添加异步功能的速度如此之快，这些特性的可用只是时间问题。

​		最后，需要更新拼接以端到端运行这个新的异步示例。使用asyncio.Create_task函数将服务器排队，以便在事件循环中执行，以便在到达await表达式时与客户机并行运行。这是导致扇出的另一种方法，其行为与asyncio.gather 功能不同:

```python
import asyncio
import contextlib
import math
import random

random.seed(1234)

import logging


# Write all output to a temporary directory
import atexit
import gc
import io
import os
import tempfile

TEST_DIR = tempfile.TemporaryDirectory()
atexit.register(TEST_DIR.cleanup)

# Make sure Windows processes exit cleanly
OLD_CWD = os.getcwd()
atexit.register(lambda: os.chdir(OLD_CWD))
os.chdir(TEST_DIR.name)


def close_open_files():
    everything = gc.get_objects()
    for obj in everything:
        if isinstance(obj, io.IOBase):
            obj.close()


atexit.register(close_open_files)

WARMER = 'Warmer'
COLDER = 'Colder'
UNSURE = 'Unsure'
CORRECT = 'Correct'

class EOFError(Exception):
    pass


class ConnectionBase:
    def __init__(self, connection):
        self.connection = connection
        self.file = connection.makefile('rb')

    def send(self, command):
        line = command + '\n'
        data = line.encode()
        self.connection.send(data)

    def receive(self):
        line = self.file.readline()
        if not line:
            raise EOFError('Connection closed')
        return line[:-1].decode()


class UnknownCommandError(Exception):
    pass


class AsyncConnectionBase:
    def __init__(self, reader, writer):  # Changed
        self.reader = reader  # Changed
        self.writer = writer  # Changed

    async def send(self, command):
        line = command + '\n'
        data = line.encode()
        self.writer.write(data)  # Changed
        await self.writer.drain()  # Changed

    async def receive(self):
        line = await self.reader.readline()  # Changed
        if not line:
            raise EOFError('Connection closed')
        return line[:-1].decode()


class AsyncSession(AsyncConnectionBase):  # Changed
    def __init__(self, *args):
        super().__init__(*args)
        self._clear_values(None, None)

    def _clear_values(self, lower, upper):
        self.lower = lower
        self.upper = upper
        self.secret = None
        self.guesses = []

    async def loop(self):  # Changed
        while command := await self.receive():  # Changed
            parts = command.split(' ')
            if parts[0] == 'PARAMS':
                self.set_params(parts)
            elif parts[0] == 'NUMBER':
                await self.send_number()  # Changed
            elif parts[0] == 'REPORT':
                self.receive_report(parts)
            else:
                raise UnknownCommandError(command)

    def set_params(self, parts):
        assert len(parts) == 3
        lower = int(parts[1])
        upper = int(parts[2])
        self._clear_values(lower, upper)

    def next_guess(self):
        if self.secret is not None:
            return self.secret

        while True:
            guess = random.randint(self.lower, self.upper)
            if guess not in self.guesses:
                return guess

    async def send_number(self):  # Changed
        guess = self.next_guess()
        self.guesses.append(guess)
        await self.send(format(guess))  # Changed

    def receive_report(self, parts):
        assert len(parts) == 2
        decision = parts[1]

        last = self.guesses[-1]
        if decision == CORRECT:
            self.secret = last

        print(f'Server: {last} is {decision}')


class AsyncClient(AsyncConnectionBase):  # Changed
    def __init__(self, *args):
        super().__init__(*args)
        self._clear_state()

    def _clear_state(self):
        self.secret = None
        self.last_distance = None

    # Example 21
    @contextlib.asynccontextmanager  # Changed
    async def session(self, lower, upper, secret):  # Changed
        print(f'Guess a number between {lower} and {upper}!'
              f' Shhhhh, it\'s {secret}.')
        self.secret = secret
        await self.send(f'PARAMS {lower} {upper}')  # Changed
        try:
            yield
        finally:
            self._clear_state()
            await self.send('PARAMS 0 -1')  # Changed

    async def request_numbers(self, count):  # Changed
        for _ in range(count):
            await self.send('NUMBER')  # Changed
            data = await self.receive()  # Changed
            yield int(data)
            if self.last_distance == 0:
                return

    async def report_outcome(self, number):  # Changed
        new_distance = math.fabs(number - self.secret)
        decision = UNSURE

        if new_distance == 0:
            decision = CORRECT
        elif self.last_distance is None:
            pass
        elif new_distance < self.last_distance:
            decision = WARMER
        elif new_distance > self.last_distance:
            decision = COLDER

        self.last_distance = new_distance

        await self.send(f'REPORT {decision}')  # Changed
        # Make it so the output printing is in
        # the same order as the threaded version.
        await asyncio.sleep(0.01)
        return decision


async def handle_async_connection(reader, writer):
    session = AsyncSession(reader, writer)
    try:
        await session.loop()
    except EOFError:
        pass


async def run_async_server(address):
    server = await asyncio.start_server(
        handle_async_connection, *address)
    async with server:
        await server.serve_forever()


async def run_async_client(address):
    # Wait for the server to listen before trying to connect
    await asyncio.sleep(0.1)

    streams = await asyncio.open_connection(*address)  # New
    client = AsyncClient(*streams)  # New

    async with client.session(1, 5, 3):
        results = [(x, await client.report_outcome(x))
                   async for x in client.request_numbers(5)]

    async with client.session(10, 15, 12):
        async for number in client.request_numbers(5):
            outcome = await client.report_outcome(number)
            results.append((number, outcome))

    _, writer = streams  # New
    writer.close()  # New
    await writer.wait_closed()  # New

    return results


async def main_async():
    address = ('127.0.0.1', 4321)

    server = run_async_server(address)
    asyncio.create_task(server)

    results = await run_async_client(address)
    for number, outcome in results:
        print(f'Client: {number} is {outcome}')


logging.getLogger().setLevel(logging.ERROR)

asyncio.run(main_async())

logging.getLogger().setLevel(logging.DEBUG)

>>>
Guess a number between 1 and 5! Shhhhh, it's 3.
Server: 5 is Unsure
Server: 4 is Warmer
Server: 2 is Unsure
Server: 1 is Colder
Server: 3 is Correct
Guess a number between 10 and 15! Shhhhh, it's 12.
Server: 14 is Unsure
Server: 10 is Unsure
Server: 15 is Colder
Server: 12 is Correct
Client: 5 is Unsure
Client: 4 is Warmer
Client: 2 is Unsure
Client: 1 is Colder
Client: 3 is Correct
Client: 14 is Unsure
Client: 10 is Unsure
Client: 15 is Colder
Client: 12 is Correct

```

​		这和预期的一样。协程版本更容易遵循，因为所有与线程的交互都被删除了。asyncio内置模块还提供了许多helper函数，并缩短了编写这样一个服务器所需的套接字样板文件的数量。

​		由于各种原因，您的用例可能更加复杂和难以移植。asyncio模块有一个大量的I/O,同步,采用协同程序和任务管理等功能能够简化你的代码(参见第62条和第63条)。一定要查看该库的[在线文档](https://docs.python.org/3/library/asyncio.html)，了解它的全部潜力。

**要点**

* Python提供了for循环的异步版本，包括语句、生成器、推导式和库助手函数，这些函数可以作为协同例程中的插入替换
* asyncio内置模块可以直接将使用线程和阻塞I/O的现有代码移植到协程和异步I/O

## 第62条 结合线程与协程，将代码顺利迁移到asyncio　

​		在前面的一条中(参见第61条)，使用asyncio实现线程阻塞I/O对TCP服务器进行了改写。转换是一次大概懂:一次性将所有代码转换为新的风格。但是，以这种方式移植大型程序很少可行。相反，通常需要增量地迁移代码库，同时根据需要更新测试，并在过程的每个步骤中验证一切工作正常。

​		为了确保这样，基本代码库需要能够使用线程阻塞I/O(参见第53条)和协程异步I/O(参见第60条)在同一时间相互兼容。实际上，这意味着需要线程能够运行协程，并且需要协程能够启动和等待线程。幸运的是，asyncio包含了内置工具，是这种相互操作变得简单明了。

​		例如，假设正在编写一个程序，该程序将日志文件合并到一个输出流中以帮助进行调试。给定输入日志的文件句柄，需要一种方法来检测是否有新数据可用并返回下一行输入。可以使用文件句柄的tell方法来检查当前读取位置是否与文件的长度匹配。当没有新数据出现时，应该引发一个异常(参见第20条):

```python
class NoNewData(Exception):
    pass


def readline(handle):
    offset = handle.tell()
    handle.seek(0, 2)
    length = handle.tell()

    if length == offset:
        raise NoNewData

    handle.seek(offset, 0)
    return handle.readline()
```

​		通过将这个函数包装在while循环中，可以将它转换为一个工作线程。当有新行可用时，调用给定的回调函数将其写入输出日志(参见第38条)。当没有可用数据时，线程会休眠，以减少因轮询新数据而导致的繁忙等待。当输入文件句柄关闭时，工作线程退出:

```python
import time

def tail_file(handle, interval, write_func):
    while not handle.closed:
        try:
            line = readline(handle)
        except NoNewData:
            time.sleep(interval)
        else:
            write_func(line)
```

​		现在，可以为每个输入文件启动一个工作线程，并将它们的输出统一到一个单个输出的文件中。下面的write函数需要使用一个Lock实例(参见第54条)来序列化对输入流的写入，并确保没有内部冲突。

```python
from threading import Lock, Thread

def run_threads(handles, interval, output_path):
    with open(output_path, 'wb') as output:
        lock = Lock()
        def write(data):
            with lock:
                output.write(data)

        threads = []
        for handle in handles:
            args = (handle, interval, write)
            thread = Thread(target=tail_file, args=args)
            thread.start()
            threads.append(thread)

        for thread in threads:
            thread.join()
```

​		

​		只要一个输入文件句柄仍然是活的，它对应的工作线程也将是活的。这意味着等待每个线程的join方法完成就足以知道整个进程已经完成。

​		给定一组输入路径和一个输出路径，可以调用run_threads并确认它按预期工作。为了演示这段代码的行为，如何创建或单独关闭输入文件句柄并不重要，输出验证函数(定义在接下来的confirm_merge中)也不重要，这就是为什么我把它们放在这里:

```python
def confirm_merge(input_paths, output_path):
    found = collections.defaultdict(list)
    with open(output_path, 'rb') as f:
        for line in f:
            for path in input_paths:
                if line.find(path.encode()) == 0:
                    found[path].append(line)

    expected = collections.defaultdict(list)
    for path in input_paths:
        with open(path, 'rb') as f:
            expected[path].extend(f.readlines())

    for key, expected_lines in expected.items():
        found_lines = found[key]
        assert expected_lines == found_lines, \
            f'{expected_lines!r} == {found_lines!r}'

input_paths = ...
handles = ...
output_path = ...
tmpdir, input_paths, handles, output_path = setup()

run_threads(handles, 0.1, output_path)

confirm_merge(input_paths, output_path)

tmpdir.cleanup()
```

​		以这个线程实现作为起点，如何以增量方式转换此代码以使用asyncio和协程呢?有两种方法:自上而下和自底向上。自顶向下意味着从代码库的最高部分(如主入口点)开始，然后向下直到作为调用层次结构的叶子的各个函数和类。当维护跨许多不同程序使用的许多公共模块时，这种方法可能很有用。通过首先移植入口点，可以等到已经在其他地方使用协程时再移植公共模块。

​		具体的步骤如下：

1. 将最顶层的函数使用async def定义而不是直接用def

2. 将所有执行I/O的调用(可能会阻塞事件循环)包装为使用asyncio.run_in_executor

3. 确保run_in_executor调用使用的资源或回调是正确同步的(例如，使用Lock或asyncio.run_coroutine_threadsafe函数)

4. 通过向下移动调用层次结构并将中间函数和方法转换为协程(遵循前三个步骤)，尝试消除get_event_loop和run_in_executor调用

   这里，对run_threads函数进行前三步转换：

```python
import asyncio

# On Windows, a ProactorEventLoop can't be created within
# threads because it tries to register signal handlers. This
# is a work-around to always use the SelectorEventLoop policy
# instead. See: https://bugs.python.org/issue33792
policy = asyncio.get_event_loop_policy()
policy._loop_factory = asyncio.SelectorEventLoop

async def run_tasks_mixed(handles, interval, output_path):
    loop = asyncio.get_event_loop()

    with open(output_path, 'wb') as output:
        async def write_async(data):
            output.write(data)

        def write(data):
            coro = write_async(data)
            future = asyncio.run_coroutine_threadsafe(
                coro, loop)
            future.result()

        tasks = []
        for handle in handles:
            task = loop.run_in_executor(
                None, tail_file, handle, interval, write)
            tasks.append(task)

        await asyncio.gather(*tasks)
```

​		在本例中，当run_in_executor方法的第一个参数为None时，循环事件运行特定的ThreadPoolExecutor(参见第59条)或默认执行器实例，本例中是函数tail_file。通过多次调用run_in_executor，而不是使用相应的await表达式，run_tasks_mixed协程会为每个输入文件分散出一行并发执行。然后asyncio.gather函数和await表达式扇入(参见第56条)到tail_file线程，知道他们全部完成。

​		通过使用syncio.run_coroutine_threadsafe，这段代码消除了对writer函数中的Lock实例的需要。这个函数允许普通的旧工作线程在本例中调用协程（write_async），并让它在事件循环中从主线程(或任何其他线程，如果必要的话)执行。这有效地将线程同步在一起，并确保所有写入输出文件的操作都只由主线程中的事件循环完成。一旦asyncio.gather awaitable被解析后，可以假设输出文件的所有写入也已经完成，因此可以关闭with语句中的输出文件句柄，而不必担心竞争条件。

​		可以验证这段代码是否如预期的那样工作。我用asyncio.run函数来启动协程并运行主事件循环:

```python
input_paths = ...
handles = ...
output_path = ...

tmpdir, input_paths, handles, output_path = setup()

asyncio.run(run_tasks_mixed(handles, 0.1, output_path))

confirm_merge(input_paths, output_path)

tmpdir.cleanup()
```

​		现在可以通过向下移动调用堆栈，将第4步应用到run_tasks_mixed函数。可以通过步骤1到3重新定义rail_file依赖函数，使其成为一个异步协程，而不是阻塞i/o：

```python
async def tail_async(handle, interval, write_func):
    loop = asyncio.get_event_loop()

    while not handle.closed:
        try:
            line = await loop.run_in_executor(
                None, readline, handle)
        except NoNewData:
            await asyncio.sleep(interval)
        else:
            await write_func(line)
```

​		这个tail_async的新实现允许将对get_event_loop和run_in_executor的调用推到堆栈下，并完全退出run_tasks_mixed函数。剩下的部分很干净，也更容易理解:

```python
input_paths = ...
handles = ...
output_path = ...

tmpdir, input_paths, handles, output_path = setup()

asyncio.run(run_tasks(handles, 0.1, output_path))

confirm_merge(input_paths, output_path)

tmpdir.cleanup()
```

​		可以继续这种迭代重构模式，并将readline转换为同步协程。然而，该函数需要如此多的阻塞文件I/O操作，因此似乎不值得移植，因为这会降低代码的清晰度并损害性能。在某些情况下，将所有内容移动到asyncio是有意义的，而在其他情况下则没有。

具体步骤如下:

1. 为试图移植的每个叶函数创建一个新的异步协程版本
2. 更改现有的同步函数，以便它们调用协程版本并运行事件循环，而不是实现任何实际行为
3. 向上移动调用层次结构的一个级别，创建另一个协同例程层，用对第1步中定义的协同例程的调用替换对同步函数的现有调用
4. 删除在步骤2中创建的协程周围的同步包装器，因为不再需要它们将各个部分粘在一起

​		对于上面的例子，我将从tail_file函数开始，因为我决定readline函数应该继续使用阻塞I/O。我可以重写tail_file，使它仅仅包装我上面定义的tail_async协程。要运行协程直到它完成，我需要为每个tail_file工作线程创建一个事件循环，然后调用它的run_until_complete方法。这个方法将阻塞当前线程并驱动事件循环，直到tail_async协程退出，实现与线程相同的行为，阻塞tail_file的I/O版本:

```python
def tail_file(handle, interval, write_func):
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

    async def write_async(data):
        write_func(data)

    coro = tail_async(handle, interval, write_async)
    loop.run_until_complete(coro)
```

​		这个新的tail_file函数是对旧函数的临时替换。可以通过再次调用run_threads来验证一切工作正常:

```python
input_paths = ...
handles = ...
output_path = ...

tmpdir, input_paths, handles, output_path = setup()

run_threads(handles, 0.1, output_path)

confirm_merge(input_paths, output_path)

tmpdir.cleanup()
```

​		用tail_file包装tail_async之后，下一步是将run_threads函数转换为协程。这与上面的自顶向下方法的第4步是相同的工作，所以在这一点上，样式是收敛的。

​		对于采用asyncio来说，这是一个很好的开始，但是还可以做更多来增加程序的响应性(参见第63条)。

**要点**

* asyncio事件循环的可等待的run_in_executor方法允许协程在ThreadPoolExecutor池中运行同步函数。这有助于自顶向下迁移到asyncio
* asyncio事件循环的run_until_complete方法允许同步代码运行协程直到其完成。asyncio.run_coroutine_threadsafe函数跨线程边界提供了相同的功能。这些都有助于自底向上迁移到asyncio