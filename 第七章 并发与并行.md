# 第七章 并发与并行

​		并发性能够让计算机看起来同时多很多事情。例如，在一台只有一个CPU内核的计算机上，如果有哪个程序在单处理器上运行，操作系统就会迅速变化。这样做时，操作系统交错地执行程序，这就展示了一种多个程序同时进行的假象。

​		相反，并行性涉到在同一时间做许多不同的事情。具有多个CPU内核的计算机可以同时执行多个程序。每个CPU内核运行一个独立程序的指令，这允许每个程序在同一时刻前进。

​		在单个程序中，并发性是一种使程序员更容易解决某些类型问题的工具。并发程序支持许多不同的执行路径，包括独立的I/O流，以一种似乎同时和独立的方式向前推进。

​		并行性和并发性之间的关键区别在于加速。当一个程序中有两条不同的路径并行前进时，完成全部工作所需要的时间就减少了一半；执行速度快了两倍。相比之下，并发程序可能会运行数千条看似并行的独立执行路径，但对总体工作没有提供加速。

​		Python有多种风格方式能够使得并发程序变得很容易写。线程支持相对较少的并发性，而协程支持大量的并发函数。Python还可以通过系统调用、子进程和C扩展完成并行工作。但是让并发的Python代码真正并行运行是非常困难的。了解如何在这不同的情况下最好的利用Python是最重要的。

## 第52条 使用subprocess管理子进程

​		Python有运行和管理子进程的可靠库。这使得它成为其他工具(如命令行实用程序)结合在一起的一种很好的语言。当现有的shell脚本变得复杂时(随着时间的推移，他们经常会变得复杂)，出于可读性和可维护性的考虑，将他们分别使用Python重写是一个自然的选择。

​		由Python启动子进程能够并行运行，是我们能够使用Python消耗机器的所有CPU内核，并最大限度地提高程序的吞吐量。虽然Python本身可能受CPU限制(参见第53条)，但使用Python来驱动和协调CPU密集型工作的负载是很容易的。

​		Python有很多方式来运行子进程(例如，os.open，os.exex*)，但是管理子进程的最佳选择是使用子进程内置模块。用子进程运行子进程非常简单。这里，使用模块的run convenience函数来启动进程，读取其输出，并验证它是否终止彻底:

```python
import subprocess
# Enable these lines to make this example work on Windows
# import os
# os.environ['COMSPEC'] = 'powershell'

result = subprocess.run(
    ['echo', 'Hello from the child!'],
    capture_output=True,
    # Enable this line to make this example work on Windows
    # shell=True,
    encoding='utf-8', shell=True)

result.check_returncode()  # No exception means it exited cleanly
print(result.stdout)
>>>
"Hello from the child!"
```

***

**注意**

​		本项目中的示例假设系统存在echo、sleep、OpenSSL命令可用。在Windows上，情况并非如此。关于如何在Windows上运行这些代码片段，参阅完整示例代码。

***

​		子进程独立于父进程(Python解析器)而运行。如果使用popen类而不是run函数创建一个子进程，可以在Python做其他工作时轮询子进程。

~~~python
proc = subprocess.Popen(['sleep', '1'], shell=True)
while proc.poll() is None:
    print('Working...')
    # Some time-consuming work here
	...
print('Exit status', proc.poll())
>>>
Working...
Working...
Working...
Working...
Working...
Working...
...
~~~

​		将子进程与父进程解耦可释放父进程以并行地运行许多子进程。在这里，通过使用Popen提前启动所有的子进程来做到这一点：

~~~python
import time
start = time.time()
sleep_procs = []
for _ in range(10):
    proc = subprocess.Popen(['sleep', '1'], shell = True)
    sleep_procs.append(proc)
~~~

​		之后，等待他们完成I/O，用通信方法结束：

~~~python
import time

start = time.time()
sleep_procs = []
for _ in range(10):
    proc = subprocess.Popen(['sleep', '1'], shell=True)
    sleep_procs.append(proc)

for proc in sleep_procs:
    proc.communicate()
end = time.time()
delta = end - start
print(f'Finished in {delta:.3} seconds')
>>>
Finished in 0.111 seconds
~~~

​		如果这些进程按照顺序进行，总的延迟将会是10s或更多，而不是测试的结果。

​		还可以将数据从Python程序传输到子进程，并检查其输出。这允许使用许多其他程序并行运行工作。例如，假设要使用OpenSSL命令工具加密一些数据。使用命令行参数和I/O管道启动子进程很简单。

~~~python
import os
# On Windows, after installing OpenSSL, you may need to
# alias it in your PowerShell path with a command like:
# $env:path = $env:path + ";C:\Program Files\OpenSSL-Win64\bin"

def run_encrypt(data):
    env = os.environ.copy()
    env['password'] = 'zf7ShyBhZOraQDdE/FiZpm/m/8f9X+M1'
    proc = subprocess.Popen(
        ['openssl', 'enc', '-des3', '-pass', 'env:password'],
        env=env,
        stdin=subprocess.PIPE,
        stdout=subprocess.PIPE,
    	shell=True)
    proc.stdin.write(data)
    proc.stdin.flush()  # Ensure that the child gets input
    return proc

~~~

​		在这里，将随机字节通过管道传输到加密函数中，但实际上，这个输入管道将从用户输入、文件句柄、网络套接字等输入数据:

~~~python
procs = []
for _ in range(3):
    data = os.urandom(10)
    proc = run_encrypt(data)
    procs.append(proc)
~~~

​		子进程并行运行并使用它们的输入。在这里，等待它们完成后，然后检索它们的最终输出。输出是随机的：

~~~python
for proc in procs:
    out, _ = proc.communicate()
    print(out[-10:])
>>>
b't\xcb|j\x8b\xf0\x96P\x85\xa0'
b'\xd5M\xd1.\xa5\xb4C\xb0\xd3_'
b'3\xc4]\x07YB\xd7X\xf1\xd8'

~~~

​		还可以创建并行进程链，就像UNIX管道一样，将一个子进程的输出连接到另一个子进程的输入，等等。下面是一个函数，它将openssl命令行工具作为子进程启动，以生成输入流的Whirlpool散列：

~~~python
def run_hash(input_stdin):
    return subprocess.Popen(
        ['openssl', 'dgst', '-whirlpool', '-binary'],
        stdin=input_stdin,
        stdout=subprocess.PIPE,
    	shell=True)
~~~

​		现在，可以启动一组进程来加密一些数据，然后启动另一组进程来对其加密的输出进行散列。这里必须注意，启动子进程管道的Python解释器进程是如何保留上游进程的stdout实例的:

~~~python
encrypt_procs = []
hash_procs = []
for _ in range(3):
    data = os.urandom(100)

    encrypt_proc = run_encrypt(data)
    encrypt_procs.append(encrypt_proc)

    hash_proc = run_hash(encrypt_proc.stdout)
    hash_procs.append(hash_proc)

    # Ensure that the child consumes the input stream and
    # the communicate() method doesn't inadvertently steal
    # input from the child. Also lets SIGPIPE propagate to
    # the upstream process if the downstream process dies.
    encrypt_proc.stdout.close()
    encrypt_proc.stdout = None
~~~

​		一旦启动子进程，它们之间的I/O将自动发生。所需要做的就是等待他们完成并打印最终输出:

```python
for proc in encrypt_procs:
    proc.communicate()
    assert proc.returncode == 0

for proc in hash_procs:
    out, _ = proc.communicate()
    print(out[-10:])
    assert proc.returncode == 0
>>>
b'\xe2j\x98h\xfd\xec\xe7T\xd84'
b'\xf3.i\x01\xd74|\xf2\x94E'
b'5_n\xc3-\xe6j\xeb[i'
```

​		如果担心子进程永远不会完成或以某种方式阻塞输入或输出管道，可以将timeout参数传递给communicate方法。如果子进程没有在指定的时间内完成，就会引发一个异常，从而可以终止行为不正常的子进程:

```python
# Use this line instead to make this example work on Windows
# proc = subprocess.Popen(['sleep', '10'], shell=True)
proc = subprocess.Popen(['sleep', '10'], shell=True)
try:
    proc.communicate(timeout=0.1)
except subprocess.TimeoutExpired:
    proc.terminate()
    proc.wait()

print('Exit status', proc.poll())
```

**要点**

* 使用子进程模块来运行子进程并管理它们的输入和输出流
* 子进程与Python解释器并行运行，使得能够最大限度地利用CPU内核
* run便利函数的简单使用，Popen类的高级使用，如unix风格的管道
* 使用通信方法的timeout参数来避免死锁和子进程挂起