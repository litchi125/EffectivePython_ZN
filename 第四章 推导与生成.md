# 第四章 推导式与生成式

​		许多编程语言都是以处理列表、字典键值对、集合为基础的。python提供了一种特殊的语法，叫做推导式(comprehensions)，用来简单的对这些类型的数据进行遍历并创建派生数据结构。推导式能够提高执行参见任务代码的可读性并且有许多的其他的好处。

​		python将这种处理风格扩展到了带有生成器(generators)的函数，它允许函数以流的形式递增地返回数据。调用生成器函数返回的结果可以用于任何迭代器(iterator,例如loops、*号表达式)。生成器可以改善性能、减少内存的使用、提高可读性。

## 第27条 尽量使用推导式而不是map和filter

​		python为从一个序列或迭代器派生新列表提供了许多的语法。这些表达式叫做列表推导式。例如，选哟计算一个列表里面元素的平凡。这里使用了简单的loop循环：

~~~python
a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
squares = []
for x in a:
squares.append(x**2)
print(squares)
>>>
[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
~~~

​		这也可以使用列表推导式，通过指定需要计算的表达式和要循环序列获取相同的结果：

~~~python
a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
squares = [x**2 for x in a] # List comprehension
print(squares)
>>>
[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
~~~

​		除非应用的是单参数的函数，针对简单的情况，列表推导式要比内置的mao函数更加清晰。map函数需要为计算创建一个lambda函数，这看上去很复杂：

~~~python
alt = map(lambda x: x ** 2, a)
~~~

​		与map不同，列表推导式可以很简单的在输入列表时过滤元素，并从结果中删除相应的输出。例如，要计算能被2整除的数的平方。这里通过循环后的列表推导式添加一个条件表达式来实现：

~~~python
even_squares = [x**2 for x in a if x % 2 == 0]
print(even_squares)
>>>
[4, 16, 36, 64, 100]

~~~

​		也可以使用map函数与内置的filter函数实现相同的结果，但是写法很难读：

~~~python
alt = map(lambda x: x**2, filter(lambda x: x % 2 == 0, a))
assert even_squares == list(alt)
~~~

​		字典和集合也有他们自己对应的列表推导式(分别叫做字典推导式dictionary comprehensions和集合推导式set comprehensions)。这使得在编写算法时容易创建其他类型的派生数据结构。

~~~python
even_squares_dict = {x: x**2 for x in a if x % 2 == 0}
threes_cubed_set = {x**3 for x in a if x % 3 == 0}
print(even_squares_dict)
print(threes_cubed_set)
>>>
{2: 4, 4: 16, 6: 36, 8: 64, 10: 100}
{216, 729, 27}
~~~

​		通过使用相应的构造函数包装每个调用，map和filter也可以获得相同的结果。这些语句太长了，所以可能需要拆分到多行，这甚至更加麻烦，应带避免

~~~python
alt_dict = dict(map(lambda x: (x, x**2),
				filter(lambda x: x % 2 == 0, a)))
alt_set = set(map(lambda x: x**3,
				filter(lambda x: x % 3 == 0, a)))
~~~

**要点**

* 列表推导式要比map和filter这些内置函数更加简单，因为他们不需要lambda表达式
* 列表推导式允许对列表中输入的元素进行筛选，而map要实现这样的功能就必须要和filter结合使用
* 字典和集合也可以通过推导式生成

## 第28条 在推导式中避免使用两个以上的子表达式

​		除了基本的用法(参见第27条)外，推导式支持多层的循环结构。例如，要把一个元素为列表结构的列表矩阵转换成一个列表。这里，通过包含两个子表达式的列表推导式实现。这些子表达式按照写定的顺序从左往右执行：

~~~python
matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
flat = [x for row in matrix for x in row]
print(flat)
>>>
[1, 2, 3, 4, 5, 6, 7, 8, 9]
~~~

​		这个示例简单、可读，并且很好的展示了列表推导式中多层循环的使用。多层循环的另一个和你用法时复制输入列表的两层深度到一个列表中。例如，要计算一个二维矩阵每一个元素的平方。这个推导式比较复杂，因为多了额外的[]，但还是比较容易阅读：

~~~python
squared = [[x**2 for x in row] for row in matrix]
print(squared)
>>>
[[1, 4, 9], [16, 25, 36], [49, 64, 81]]

~~~

​		如果列表推导式包含了其他的循环，就会变得很长，就不得不拆分成多行：

~~~python
my_lists = [
    [[1, 2, 3], [4, 5, 6]],
    ...
    ]
flat = [x for sublist1 in my_lists
        for sublist2 in sublist1
        for x in sublist2]

~~~

​		在这一方面，多行推导式并不会比循环写法少多少代码。这里，使用普通循环来实现相同的效果。这个版本的缩进使得循环比商城列表推导式更加容易理解：

~~~python
flat = []
for sublist1 in my_lists:
	for sublist2 in sublist1:
		flat.extend(sublist2)

~~~

​		导式支持多层if结构。相同循环级别的多个条件具有隐式和表达式。例如，要过滤一个列表中的大于4的偶数。下面的两个列表推导式效果相同：

~~~python
a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
b = [x for x in a if x > 4 if x % 2 == 0]
c = [x for x in a if x > 4 and x % 2 == 0]
~~~

​		也可以在for子表达式之后的每一级循环中指定条件。例如，要找出一个矩阵中，每一行所有元素总和大于等于10，且元素为3的整数倍的元素。虽然通过推导式来实现这个表达式并不需要多少代码，但是可读性很差：

~~~python
matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
filtered = [[x for x in row if x % 3 == 0]
for row in matrix if sum(row) >= 10]
print(filtered)
>>>
[[6], [9]]

~~~

​		尽管这个示例有点复杂，但在实践中您将看到这种推导式似乎非常适合的情况。这里强烈建议你避免像这样的列表、字典或结合推导式。对于阅读代码的人来说这很难读懂。对于字典推导式，混淆的可能性更大，因为它们已经需要一个额外的参数来表示每个项的键和值。

​		这里的经验之谈是在理解过程中避免使用两个以上的控制子表达式。这可以是两个条件，两个循环，或者一个条件和一个循环。一旦它变得更复杂，您应该使用普通的if和for语句，并编写一个帮助函数。

**要点**

* 推导式支持多层循环，并对每层循环支持多个条件表达式
* 一旦推导式拥有两个以上的子表达式，就很难读，应该避免这种情况

## 第29条 避免使用赋值表达式在推导式中重复操作

​			推导式(包含列表、字典和集合变体)的参见模式时需要在多个位置引用相同的计算。例如，要写一个程序来管理一家固件公司的订单。由于新订单来自顾客，需要程序告诉我能否完成他们的订单。这就需要验证一个请求是否有足够的库存并是否超过当前运输的最低门槛：

~~~python
stock = {
    'nails': 125,
    'screws': 35,
    'wingnuts': 8,
    'washers': 24,
}
order = ['screws', 'wingnuts', 'clips']
def get_batches(count, size):
	return count // size
result = {}
for name in order:
	count = stock.get(name, 0)
batches = get_batches(count, 8)
if batches:
	result[name] = batches
print(result)
>>>
{'screws': 4, 'wingnuts': 1}
~~~

​		这里通过使用字典推导式让循环逻辑更高效(参见第27条)：

~~~python
found = {name: get_batches(stock.get(name, 0), 8)
		for name in order
   		if get_batches(stock.get(name, 0), 8)}
print(found)
>>>
{'screws': 4, 'wingnuts': 1}
~~~

​		尽管代码比较紧凑，但是问题是get_batches(stock.get(name, 0), 8) 表达式是重复的。这会增加技术上不必要的视觉干扰，从而降低了可读性。如果两个表达式没有保持同步，还会增加引入bug的可能性。例如，将第一个get_batches的第二个参数改为4，而不是8就会导致结果不同：

~~~python
has_bug = {name: get_batches(stock.get(name, 0), 4)
			for name in order
			if get_batches(stock.get(name, 0), 8)}
print('Expected:', found)
print('Found: ', has_bug)
>>>
Expected: {'screws': 4, 'wingnuts': 1}
Found: {'screws': 8, 'wingnuts': 2}

~~~

​		解决这个问题的简单方法是使用python3.8才支持的海象表达式(:=)，能够将赋值表达式编程推导式的一部分(参见第10条)

~~~python
found = {name: batches for name in order
		 if (batches := get_batches(stock.get(name, 0), 8))}
~~~

​		赋值表达式(batches := get_batches(...))允许我们在stock字典中查找订单键一次，调用get_batches一次，并将其对应的值存储在批变量中。然后，可以在推导式的其他地方引用该变量来构造字典中的内容，并且不需要二次调用get_batches。消除对get和get_batches处理的冗余调用，还可以通过通过避免对顺序列表中的每个项进行不必要的计算来提高性能。

​		将赋值表达式用到推导式的值表达式上是有效的。但是如果尝试在推导式的其他部分引用它定义的变量，可能会在运行时遇到异常，以为推导式的计算顺序不同：

~~~python
result = {name: (tenth := count // 10)
			for name, count in stock.items() if tenth > 0}
>>>
Traceback ...
NameError: name 'tenth' is not defined
~~~

​		可以通多移动赋值表达式到条件中，然后引用他在推导式中定义的变量名来修估这个示例：

~~~python
result = {name: tenth for name, count in stock.items()
			if (tenth := count // 10) > 0}
print(result)
>>>
{'nails': 12, 'screws': 3, 'washers': 2}
~~~

​		如果在推导式的赋值部分使用了海象表达式，而没有任何条件，就会让循环变量泄露到当前的作用域外(参见第21条)：

~~~python
half = [(last := count // 2) for count in stock.values()]
print(f'Last item of {half} is {last}')
>>>
Last item of [62, 17, 4, 12] is 12

~~~

​		这个循环变量泄露和普通for循环造成的结果相似：

~~~python
for count in stock.values(): # Leaks loop variable
pass
print(f'Last item of {list(stock.values())} is {count}')
>>>
Last item of [125, 35, 8, 24] is 24

~~~

​		然而，对于推导式中的循环变量，类似的泄露不会发生：

~~~python
half = [count // 2 for count in stock.values()]
print(half) # Works
print(count) # Exception because loop variable didn't leak
>>>
[62, 17, 4, 12]
Traceback ...
NameError: name 'count' is not defined

~~~

​		最好避免循环变量，建议只在推导式的条件部分使用赋值表达式。

​		是哦那个赋值表达式的操作同样适用于生成器表达式(参见第32条)。这里，创建了一个包含item名称和stock中当前计数的迭代器，而不是dict实例:

~~~python
found = ((name, batches) for name in order
			if (batches := get_batches(stock.get(name, 0), 8)))
print(next(found))
print(next(found))
>>>
('screws', 4)
('wingnuts', 1)
~~~

**要点**

* 赋值表达式使得推导式和生成器表达式可以重用同一推导式中某个条件的值，这可以提高可读性和性能
* 尽管可以在推导式表达式或生成器表达式的条件之外使用赋值表达式，但应该避免这样做。

## 第30条 使用生成器代替直接返回列表

​		对于产生结果序列函数，最简单的是返回元素组成的列表。例如，假设要找到一个字符串中各个单词的索引。这里首先使用append方法见结果追加到一个列表中，并在函数的结尾返回：

~~~python
def index_words(text):
    result = []
    if text:
    	result.append(0)
        for index, letter in enumerate(text):
        if letter == ' ':
        	result.append(index + 1)
    return result

~~~

​		这种方法能够针对一些输入样本，返回正确结果：

~~~python
address = 'Four score and seven years ago...'
result = index_words(address)
print(result[:10])
>>>
[0, 5, 11, 15, 21, 27, 31, 35, 43, 51]
~~~

​		使用这个中法有两个问题：

​		第一个问题是，代码看起来很复杂。每到有一个单词就需要调用一次append方法。

这种方法调用的bulk(result.append)弱化了要追加到列表(index +1)位置的值。一行代码用于创建结果列表，另一行用户返回结果列表。虽然函数整体包含了130多个字符(不包含空格)，但只有75个字符时重要的。

​		通过生成器(generator)来构建这个函数才是更好的方法。生成器通过使用yield关键字产生结果。这里，定义一个生成器函数来获取相同的结果：

~~~python
def index_words_iter(text):
    if text:
    	yield 0
    for index, letter in enumerate(text):
        if letter == ' ':
        yield index + 1
~~~

​		但调用函数是，生成器函数不会立即运行，而是返回一个迭代器。只有调用内置的next函数，生成器才会执行迭代器表达式。生成器传递给yield的每个值都由迭代器返回给调用者：

~~~python
it = index_words_iter(address)
print(next(it))
print(next(it))
>>>
0
5
~~~

​		index_words_iter函数非常容易阅读，因为它消除了与结果列表的所有交互。结果被传递给yield表达式代替。如果需要，可以将生成器返回的迭代器传递给列表内置函数，从而轻松地将其转换为列表(参见第32条)：

~~~python
result = list(index_words_iter(address))
print(result[:10])
>>>
[0, 5, 11, 15, 21, 27, 31, 35, 43, 51]
~~~

​		index_words函数的第二个问题是，所有需要的结果在函数返回之前都必须存储在list中。如果函数的输入值非常巨大，就可能导致内存溢出而崩溃的问题。

​		相比之下，这个函数的生成器版本就可以很容易地适应任意长度的输入，因为它的内存需求是有限的。例如，这里定义一个生成器，他从文件中一行一行的输入，并输出每一个单词：

~~~python
def index_file(handle):
    offset = 0
    for line in handle:
        if line:
        	yield offset
        for letter in line:
            offset += 1
            if letter == ' ':
            	yield offset
~~~

​		这个函数的最大工作内存就是文件中最长行长度。这个函数可以获得相同的输出(参见第36条)：

~~~python
with open('address.txt', 'r') as f:
    it = index_file(f)
    results = itertools.islice(it, 0, 10)
print(list(results))
>>>
[0, 5, 11, 15, 21, 27, 31, 35, 43, 51]
~~~

​		定义这样的生成器的唯一问题是，调用者必须知道返回的迭代器是有状态的，不能重用(参见第31条)。

**要点**

* 使用生成器比使用函数返回累积结果列表更清晰
* 生成器返回的迭代器将生成一组传递给生成器函数体中的yield表达式的值
* 生成器可以为任意大的输入产生一系列输出，因为它们的工作内存不包括所有的输入和输出

## 第31条 当迭代参数时要保持警惕

​		当一个函数接受一个对象列表作为参数时，对该列表进行多次迭代通常是很重要的。例如，假设我想分析美国德克萨斯州的旅游数据。假设数据集是每个城市的游客数量(以每年数百万计)。我想算出每个城市接待的游客占总游客的百分比。

​		为了实现目的，我需要一个归一化函数，将输入加起来，以确定每年的游客总数，然后将每个城市的个人游客总数除以总人数，得出该城市对整体的贡献:

~~~python
def normalize(numbers):
    total = sum(numbers)
    result = []
    for value in numbers:
        percent = 100 * value / total
        result.append(percent)
    return result
~~~

​		当输入参数为游客列表时，函数可以正常工作：

~~~python
visits = [15, 35, 80]
percentages = normalize(visits)
print(percentages)
assert sum(percentages) == 100.0
>>>
[11.538461538461538, 26.923076923076923, 61.53846153846154]
~~~

​		为了扩大规模，我需要从一个包含德州所有城市的文件中读取数据。我定义一个生成器来做这个，因为之后我可以重用相同的函数，当我想计算整个世界的旅游数字时——一个需要更高内存需求的更大的数据集(参见第30条)：

~~~python
def read_visits(data_path):
    with open(data_path) as f:
    	for line in f:
    		yield int(line)
~~~

​		令人惊讶的是，在read_visits生成器的返回值上调用normalize不会产生任何结果:

~~~python
it = read_visits('my_numbers.txt')
percentages = normalize(it)
print(percentages)
>>>
[]

~~~

​		发生此行为是因为迭代器只生成一次结果。如果迭代器或生成器已经引发了StopIteration异常，那么第二次迭代不会得到任何结果：

~~~python
it = read_visits('my_numbers.txt')
print(list(it))
print(list(it)) # Already exhausted
>>>
[15, 35, 80]
[]
~~~

​		令人困惑的是，在迭代一个已经耗尽的迭代器时也不会出现错误。for循环、列表构造函数和Python标准库中的许多其他函数都希望在正常操作期间引发StopIteration异常。这些函数无法区分没有输出的迭代器和有输出但现在耗尽的迭代器之间的区别。

​		要解决这个问题，可以显式地耗尽一个输入迭代器，并将其全部内容的副本保存在一个列表中。然后，您可以根据需要遍历数据的列表版本。这是与之前相同的函数，但它防御性地复制了输入迭代器：

~~~python
def normalize_copy(numbers):
    numbers_copy = list(numbers) # Copy the iterator
    total = sum(numbers_copy)
    result = []
    for value in numbers_copy:
        percent = 100 * value / total
        result.append(percent)
    return result
~~~

​		现在这个函数就可以正确的处理通过read_visits生成器返回的结果：

~~~python
it = read_visits('my_numbers.txt')
percentages = normalize_copy(it)
print(percentages)
assert sum(percentages) == 100.0
>>>
[11.538461538461538, 26.923076923076923, 61.53846153846154]
~~~

​		这种方法的问题是，输入迭代器内容的副本可能非常大。复制迭代器可能会导致程序耗尽内存并崩溃。这种潜在的不确定问题，就是不我首先将read_visits作为生成器编写的原因。解决这个问题的一种方法是接受一个每次被调用都会返回一个新的迭代器的函数:

~~~python
def normalize_func(get_iter):
    total = sum(get_iter()) # New iterator
    result = []
    for value in get_iter(): # New iterator
        percent = 100 * value / total
    	result.append(percent)
    return result

~~~

​		为了使用normalize_func函数，需要在每次调用生成器时传递一个lambda表达式创建一个新的迭代器：

~~~python
path = 'my_numbers.txt'
percentages = normalize_func(lambda: read_visits(path))
print(percentages)
assert sum(percentages) == 100.0
>>>
[11.538461538461538, 26.923076923076923, 61.53846153846154]
~~~

​		虽然这样做是可行的，但是必须像这样传递lambda函数是很笨拙的。实现相同结果的更好方法是提供一个实现迭代器协议(iterator protocol)的新容器类。

​		迭代器协议是Python for循环和相关表达式遍历容器类型内容的方式。当Python看到一个for x in foo表达式时，它实际上会调用iter(foo)。内置函数iter调用foo.--iter--特殊方法。--iter--方法必须返回一个迭代器对象(其本身实现了--next--特殊方法)。然后，for循环反复调用迭代器对象上的下一个内置函数，直到耗尽它(通过引发StopIteration异常来指示)。

​		这听起来很复杂，但实际上，通过类中定义--iter--方法实现生成器。在这里，定义了一个可迭代的容器类，它读取包含旅游数据的文件：

~~~python
class ReadVisits:
    def __init__(self, data_path):
    	self.data_path = data_path
    def __iter__(self):
    	with open(self.data_path) as f:
    		for line in f:
    			yield int(line)
~~~

​		这个新的容器类型在没有修改的情况下传递给原始函数时可以正确工作：

~~~python
visits = ReadVisits(path)
percentages = normalize(visits)
print(percentages)
assert sum(percentages) == 100.0
>>>
[11.538461538461538, 26.923076923076923, 61.53846153846154]

~~~

​		这是因为normalize中的sum方法调用了ReadVisit.--iter--来分配一个新的迭代器对象。用于规范化数字的for循环还调用--iter--来分配第二个迭代器对象。每一个迭代器都将被独立地推进和使用，以确保每个唯一的迭代都能看到所有的输入数据值。这种方法唯一的缺点是它多次读取输入数据。

​		既然已经了解了ReadVists这样的容器是如何工作的，那么您就可以编写函数和方法来确保形参不仅仅是迭代器。协议规定，当一个迭代器被传递给iter内置函数时，iter返回迭代器本身。相反，当容器类型被传递给iter时，每次都会返回一个新的迭代器对象。因此，你可以测试这个行为的输入值，并抛出TypeError来拒绝不能重复迭代的参数:

~~~python
def normalize_defensive(numbers):
    if iter(numbers) is numbers: # An iterator -- bad!
   		raise TypeError('Must supply a container')
    total = sum(numbers)
    result = []
    for value in numbers:
        percent = 100 * value / total
        result.append(percent)
    return result

~~~

​		collections.abc内置模块定义了一个literator类，可以在通过isinstance测试潜在的问题提(参见第43条)：

~~~python
from collections.abc import Iterator
def normalize_defensive(numbers):
    if isinstance(numbers, Iterator): # Another way to check
    	raise TypeError('Must supply a container')
    total = sum(numbers)
    result = []
    for value in numbers:
        percent = 100 * value / total
        result.append(percent)
    return result
~~~

​		如果不想像上面的normalize_copy函数那样复制完整的输入迭代器，那么使用容器的方法是理想的，但是还需要对输入数据进行多次迭代。对于list和ReadVisits输入，此函数的工作原理与预期一致，因为它们是遵循迭代器协议的可迭代容器:

~~~python
visits = [15, 35, 80]
percentages = normalize_defensive(visits)
assert sum(percentages) == 100.0
visits = ReadVisits(path)
percentages = normalize_defensive(visits)
assert sum(percentages) == 100.0
~~~

​		如果输入是迭代器而不是容器，该函数将引发异常：

~~~pythn
visits = [15, 35, 80]
it = iter(visits)
normalize_defensive(it)
>>>
Traceback ...
TypeError: Must supply a container
~~~

​		同样的方法也可以用于异步迭代器(参见第61条)

**要点**

* 注意多次遍历输入参数的函数和方法。如果这些参数是迭代器，您可能会看到奇怪的行为和丢失的值
* Python的迭代器协议定义了容器和迭代器如何与iter和下一个内置函数、for循环和相关表达式交互
* 通过将--iter--方法实现为生成器，可以轻松定义自己的可迭代容器类型
* 如果在一个值上调用iter产生的值与传入的值相同，则可以检测该值是迭代器(而不是容器)。或者，也可以使用内置的isinstance函数以及collections.abc.Iterator类进行检测

## 第32条 考虑用于大列表推导式的生成器表达式

​		列表推导式(参见第27条)的问题是，它们可能会为输入序列中的每个值创建包含一个项的新列表实例。这对较小的输入来说是友好的，但是但输入比较大时，这可能导致大量内存消耗并导致程序崩溃。

​		例如，假设我想读取一个文件并返回每行的字符数。如果使用列表推导式操作，则需要在内存中保存文件的每一行的长度。如果文件非常庞大，或者可能是一个永无止尽的网络套接字，那么使用列表推导式将会有问题。在这里，我以一种只能处理小输入值的方式使用列表推导式：

~~~python
value = [len(x) for x in open('my_file.txt')]
print(value)
>>>
[100, 57, 15, 1, 12, 75, 5, 86, 89, 11]
~~~

​		为了结果这个问题，Python提供了生成器表达式，它是列表推导式和生成器的泛化。生成器表达式在运行时不会具体化整个输出序列。相反，生成器表达式计算为一个迭代器，该迭代器每次从表达式中生成一个项。

​		可以在()中写类似列表推导式的语法构造生成器表达式。这里，使用生成器表达式获取和上面代码相同的结果。但是，生成器表达式会立即计算为迭代器，并且不会继续前进：

~~~python
it = (len(x) for x in open('my_file.txt'))
print(it)
>>>
<generator object <genexpr> at 0x108993dd0>

~~~

​		返回的迭代器可以在需要时(使用下一从个内置函数)一步一步地从生成器表达式生成下一个输出。可以尽可能多地使用生成器表达式，而不会冒内存使用量激增的风险：

~~~python
print(next(it))
print(next(it))
>>>
100
57
~~~

​		生成器表达式的另一个强大的结果是它们可以组合在一起。在这里，我使用上面的生成器表达式返回的迭代器，并将其用作另一个生成器表达式的输入：

~~~python
roots = ((x, x**0.5) for x in it)
~~~

​		每次我推进这个迭代器时，它也会推进内部迭代器，创建循环、计算条件表达式、传递输入和输出的多米诺效应，同时尽可能提高内存效率:

~~~python
print(next(roots))
>>>
(15, 3.872983346207417)
~~~

​		像这样将生成器链接在一起，在Python中执行得非常快。当正在寻找一种方式来组合在大量输入流上操作的功能时，生成器表达式是一个很好的选择。唯一的问题是，生成器表达式返回的迭代器是有状态的，所以必须小心不要多次使用这些迭代器

**要点**

* 列表推导式可能会由于输入过大导致内存溢出问题
* 生成器表达式通过迭代器一次产生一个输出避免内存过大问题
* 生成器表达式可以通过将迭代器从一个生成器表达式传递到另一个生成器表达式的for子表达式来组成
* 生成器表达式在连接在一起时执行得非常快，并且内存效率很高

## 第33条 使用yield from组成多个生成器

​		生成器提供了很多好处(参见第30条)并能结果常见问题(参见第31条)。生成器非常有用，以至于许多程序开始看起来就像是串联在一起的生成器层。

​		例如，假设有一个图形程序，它使用生成器来动画屏幕上的图像移动。为了得到想要的视觉效果，需要图像一开始快速移动，然后短暂暂停，然后继续以较慢的速度移动。在这里，定义了两个生成器，为动画的每个部分生成预期的屏幕增量:

~~~python
def move(period, speed):
    for _ in range(period):
    	yield speed
def pause(delay):
    for _ in range(delay):
    	yield 0
~~~

​		为了创建最终的动画，需要将move和pause结合在一起，以产生单一序列的屏幕增量。在这里，我通过为nimation的每个步骤调用生成器来实现这一点，依次遍历每个生成器，然后从所有生成器中依次生成增量

~~~python
def animate():
    for delta in move(4, 5.0):
    	yield delta
    for delta in pause(3):
    	yield delta
    for delta in move(2, 3.0):
   		yield delta
~~~

​		现在，我可以在屏幕上渲染那些由单个动画生成器生成的增量：

~~~python
def render(delta):
    print(f'Delta: {delta:.1f}')
    # Move the images onscreen
    ...
def run(func):
    for delta in func():
    	render(delta)
run(animate)
>>>

Delta: 5.0
Delta: 5.0
Delta: 5.0
Delta: 5.0
Delta: 0.0
Delta: 0.0
Delta: 0.0
Delta: 3.0
Delta: 3.0
~~~

​		这段代码的问题在于动画函数的重复性。每个生成器的for语句和冗余的yield表达式增加了噪音并降低了可读性。这个例子只包含三个嵌套生成器，它已经损害了清晰度;一个包含十几个或更多阶段的复杂动画是非常难以理解的。

​		解决这个问题的方法是使用yield from表达式。这个高级生成器特性允许您在将控件返回给父生成器之前，从嵌套生成器生成所有值。在这里，我使用yield from重新实现动画函数:

~~~python
def animate_composed():
    yield from move(4, 5.0)
    yield from pause(3)
    yield from move(2, 3.0)
run(animate_composed)
>>>
Delta: 5.0
Delta: 5.0
Delta: 5.0
Delta: 5.0
Delta: 0.0
Delta: 0.0
Delta: 0.0
Delta: 3.0
Delta: 3.0

~~~

​		结果和之前的一样，但是代码更加清晰并且更加直观。从本质上来说，yield from会导致Python解释器处理嵌套的for循环，并为生成表达式样板文件，从而获得更好的性能。在这里，我使用timeit内置模块运行微基准测试来验证加速效果：

~~~python
import timeit


def child():
    for i in range(1000000):
        yield i


def slow():
    for i in child():
        yield i


def fast():
    yield from child()
baseline = timeit.timeit(
    stmt='for _ in slow(): pass',
    globals=globals(),
    number=50)
print(f'Manual nesting {baseline:.2f}s')

comparison = timeit.timeit(
    stmt='for _ in fast(): pass',
    globals=globals(),
    number=50)
print(f'Composed nesting {comparison:.2f}s')
reduction = -(comparison - baseline) / baseline
print(f'{reduction:.1%} less time')
>>>
Manual nesting 4.02s
Composed nesting 3.47s
13.5% less time
~~~

​		如果您发现自己在编写生成器，我强烈建议您尽可能使用yield from。

**要点**

* yield from表达式允许您将多个嵌套生成器组合成单个组合生成器
* Yield from提供了比手动迭代嵌套生成器并生成其输出更好的性能

## 第34条 避免使用send向生成器注入数据

​		Yield表达式为生成器函数提供了一种生成可迭代输出值系列的简单方法(参见第30条)。然而，这个通道似乎是单向的:没有显而易见的方法可以在生成器运行时同时输入和输出数据。拥有这样的双向通信对于各种用例都是有价值的。

​		例如，假设我正在编写一个程序来使用软件定义的无线电发送信号。在这里，我使用一个函数生成一个具有给定点数的正弦波近似值:

~~~python
import math


def wave(amplitude, steps):
    step_size = 2 * math.pi / steps
    for step in range(steps):
        radians = step * step_size
        fraction = math.sin(radians)
        output = amplitude * fraction
        yield output
~~~

​		现在，我可以通过在波发生器上迭代来以一个指定的振幅发送波信号：

~~~python
import math


def wave(amplitude, steps):
    step_size = 2 * math.pi / steps
    for step in range(steps):
        radians = step * step_size
        fraction = math.sin(radians)
        output = amplitude * fraction
        yield output


def transmit(output):
    if output is None:
        print(f'Output is None')
    else:
        print(f'Output: {output:>5.1f}')


def run(it):
    for output in it:
        transmit(output)


run(wave(3.0, 8))
>>>
Output:   0.0
Output:   2.1
Output:   3.0
Output:   2.1
Output:   0.0
Output:  -2.1
Output:  -3.0
Output:  -2.1
~~~

​		这可以很好地产生基本波形，但它不能用于不断变化的波的振幅基于一个单独的输入(即，需要广播AM无线电信号)。我需要一种方法来调节发电机每次迭代的振幅。

​	Python生成器支持send方法，它将yield表达式升级为双向通道。send方法可用于在生成输出的同时向生成器提供流输入。通常，在迭代生成器时，yield表达式的值为None:

```python
def my_generator():
    received = yield 1
    print(f'received = {received}')


it = iter(my_generator())
output = next(it)  # Get first generator output
print(f'output = {output}')
try:
    next(it)  # Run generator until it exits
except StopIteration:
    pass
>>>
output = 1
received = None
```

​		当调用send方法，而不是使用for循环或下一个内置函数迭代生成器时，所提供的形参将在恢复生成器时成为yield表达式的值。但是，当生成器第一次启动时，还没有遇到yield表达式，所以最初调用send的唯一有效值是None(任何其他参数都会在运行时引发异常)。

~~~python
it = iter(my_generator())
output = it.send(None) # Get first generator output
print(f'output = {output}')
try:
    it.send('hello!') # Send value into the generator
except StopIteration:
    pass
~~~

​		可以利用这种行为来调制基于输入信号的正弦波的振幅。首先，需要改变波发生器，保存由yield表达式返回的振幅，并使用它来计算下一个生成的输出:

~~~python
def wave_modulating(steps):
    step_size = 2 * math.pi / steps
    amplitude = yield # Receive initial amplitude
    for step in range(steps):
        radians = step * step_size
        fraction = math.sin(radians)
        output = amplitude * fraction
        amplitude = yield output # Receive next amplitude

~~~

​		然后，我需要更新运行函数，以在每次迭代时将调制振幅流输入wave_modulating generator。要发送的第一个输入必须是None，因为yield表达式还不会在生成器中出现:

~~~python
def run_modulating(it):
    amplitudes = [
    None, 7, 7, 7, 2, 2, 2, 2, 10, 10, 10, 10, 10]
    for amplitude in amplitudes:
        output = it.send(amplitude)
        transmit(output)
run_modulating(wave_modulating(12))
>>>
Output is None
Output: 0.0
Output: 3.5
Output: 6.1
Output: 2.0
Output: 1.7
Output: 1.0
Output: 0.0
Output: -5.0
Output: -8.7
Output: -10.0
Output: -8.7
Output: -5.0
~~~

​		这样可以获得正确的结果；它能够根据输入信号适当的改变输出幅度。第一个输出如预期的那样是None，因为直到初始值yield表达式执行完后，振幅的值才会被生成器接收。

​		这段代码的一个问题是，新读者很难理解:在赋值语句的右侧使用yield并不直观，而且如果不了解这种高级生成器特性的细节，很难看到yield和send之间的连接。

​		现在，假设程序的需求变得更加复杂。不是适用一个简单的正弦波作为载波，而是需要一个复杂的波形组成过个信号序列。解决该问题的一种方法是使用yield from表达式将多个生成器组合在一起(参见第33条)。这里，可以确认的是，在振幅固定的情况下，这会和预期的一样工作：

~~~python
def complex_wave():
    yield from wave(7.0, 3)
    yield from wave(2.0, 4)
    yield from wave(10.0, 5)
run(complex_wave())
>>>
Output: 0.0
Output: 6.1
Output: -6.1
Output: 0.0
Output: 2.0
Output: 0.0
Output: -2.0
Output: 0.0
Output: 9.5
Output: 5.9
Output: -5.9
Output: -9.5
~~~

​		假设yield from可以处理更简单的情况，就可能希望它能与生成器的send方法一起正常工作了。这里，尝试通过多次调用wave_modulating生成器的组合来使用它：

~~~python
def complex_wave_modulating():
    yield from wave_modulating(3)
    yield from wave_modulating(4)
    yield from wave_modulating(5)
run_modulating(complex_wave_modulating())
>>>
Output is None
Output: 0.0
Output: 6.1
Output: -6.1
Output is None
Output: 0.0
Output: 2.0
Output: 0.0
Output: -10.0
Output is None
Output: 0.0
Output: 9.5
Output: 5.9
~~~

​		这能够很好的运行，但是这个结果却是出乎意料：输出结果中output有很多None。为什么会发生这样的情况呢？当每个yield from表达式在嵌套生成器上完成迭代时，它将移动到下一个。每个嵌套生成器都以一个纯yield表达式开始——一个没有值的表达式——以便从生成器发送方法调用接收初始振幅。这将导致父生成器在子生成器之间转换时输出None值。

​		这意味着，如果试图将它们一起使用，那么关于yield from和send单独运行时的结果将完全不同。虽然可以通过增加run_modulating函数的复杂性来解决这个None问题，但这样做并不值得。代码的新读者已经很难理解发送是如何工作的。这种令人惊讶的收益让情况变得更糟。我的建议是完全避免send方法，采用更简单的方法。

​		最简单的解决方案是向波函数传递迭代器。迭代器应该在每次调用下一个内置函数时返回一个输入振幅。这种安排确保在处理输入和输出时，每个发电机都以级联的方式进行(参见第32条)：

~~~python
def wave_cascading(amplitude_it, steps):
    step_size = 2 * math.pi / steps
    for step in range(steps):
        radians = step * step_size
        fraction = math.sin(radians)
        amplitude = next(amplitude_it) # Get next input
        output = amplitude * fraction
        yield output
~~~

​		可以将相同的迭代器传给想要组合在一起的每个生成器函数。迭代器是有状态的(参见第31条)，因此每个嵌套的生成器从前一个生成器离开的地方开始：

~~~python
def complex_wave_cascading(amplitude_it):
    yield from wave_cascading(amplitude_it, 3)
    yield from wave_cascading(amplitude_it, 4)
    yield from wave_cascading(amplitude_it, 5)
~~~

​		现在，可以通过简单地从振幅列表中传入一个迭代器来运行组合生成器：

~~~python
def run_cascading():
    amplitudes = [7, 7, 7, 2, 2, 2, 2, 10, 10, 10, 10, 10]
    it = complex_wave_cascading(iter(amplitudes))
    for amplitude in amplitudes:
        output = next(it)
        transmit(output)
run_cascading()
>>>
Output: 0.0
Output: 6.1
Output: -6.1
Output: 0.0
Output: 2.0
Output: 0.0
Output: -2.0
Output: 0.0
Output: 9.5
Output: 5.9
Output: -5.9
Output: -9.5
~~~

​		这种方法最好的部分是迭代器可以来自任何地方，并且可以是完全动态的(例如，使用生成器函数实现)。唯一的缺点是，该代码假定输入生成器是完全线程安全的，但事实可能并非如此。如果您需要跨线程边界，异步函数可能是一个更好的选择(参见第62条)

**要点**

* send方法可以通过给yield表达式赋值给变量来将数据注入到生成器中
* 使用send和yield from表达式可能会导致令人惊讶的行为，例如在生成器输出中出现意外的None值

